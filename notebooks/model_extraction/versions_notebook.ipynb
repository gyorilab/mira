{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65b0cf2f",
   "metadata": {},
   "source": [
    "# Workflow for MIRA equations extractions - notes\n",
    "\n",
    "This notebook outlines ideas for prompting for extracting mathematical equations from PDFs in the MIRA framework.\n",
    "\n",
    "---\n",
    "\n",
    "## One-shot Prompting:\n",
    "The basic workflow of MIRA is a one-shot prompting architecture (let's call this **verison = 001**).\n",
    "\n",
    "\n",
    "Process of the extraction: *'mira/notebooks/llm_extraction.ipynb'*\n",
    "\n",
    "Pipeline: *'mira/sources/sympy_ode/llm_util.py'\n",
    "\n",
    "Prompts: *'mira/sources/sympy_ode/constants.py'*\n",
    "\n",
    "Detailed results can be found in the notebook: *mira_llm_extraction_evaluation.ipynb*\n",
    "\n",
    "---\n",
    "\n",
    "## Iterative promting workflow:\n",
    "**version = 002**\n",
    "\n",
    "To improve the precision of the extraction, an iterative workflow is being introduced, with the following steps:\n",
    "### Agent 1:\n",
    "First, an extraction agent uses the original MIRA process to convert equation images into SymPy code and ground biological concepts. \n",
    "\n",
    "### Agent 2:\n",
    "Then, a validation agent checks the extraction for execution errors (missing imports, undefined variables), parameter consistency issues, and incorrect concept grounding. \n",
    "If errors are found, the validation agent corrects them and the process repeats for up to 3 iterations until all checks pass. \n",
    "\n",
    "This multi-agent approach improves extraction accuracy by catching and fixing common errors that the single-shot method might miss, while maintaining backward compatibility with the existing MIRA codebase.\n",
    "\n",
    "### RESULTS OF IMPLEMENTATION:\n",
    "*Forked version on GitHub: *'fruzsedua/mira/tree/extraction-development'*\n",
    "\n",
    "Examples for each result found in this folder: *'mira/notebooks/equation extraction development/extraction error check/string mismatch check/comparison_results_version002'*\n",
    "\n",
    "Process of the extraction: *'mira/notebooks/llm_extraction.ipynb'* -> **More detalied process**\n",
    "\n",
    "Pipeline: *'mira/sources/sympy_ode/llm_util.py' -> **New functions added**\n",
    "\n",
    "Prompts: *'mira/sources/sympy_ode/constants.py'* -> **Error handling prompt added**\n",
    "**\n",
    "**Image extraction:**\n",
    "- Additional rules added: symmetry, transmission structure, patterns, mathematical structure, parameter consistency, completeness check\n",
    "- Epidemology based rules are just ideas (from Claude) -> *revision needed!*\n",
    "\n",
    "**Error checking and correcting:**\n",
    "- Execution errors are mostly fixed during iteration 1:\n",
    "- Syntax rules for detecting and handling functions/symbols\n",
    "- Handling of imports, utilizing their names precisely\n",
    "- Missing parameters are included\n",
    "\n",
    "- Data cannot be parsed if the output format of the prompt is not aligned with the next function -> exact clarification is added to the prompt\n",
    "- Comparing number of factors to the original (count * operators and variables)\n",
    "- Preserving content between iterations of the error handling prompt\n",
    "- Missing /N fixed\n",
    "\n",
    "**Comparison of the extracted odes added:**\n",
    "- Sympy format matching\n",
    "- Sorting of equations (based on the variable on the LHS) for comparison\n",
    "- Template Model → Mtx odes confuses a lot of information due to multiple formatting steps -> *fix needed!*\n",
    "\n",
    "\n",
    "Error handling multi-agent architecture is part of the tm creation \n",
    "pipeline:\n",
    "\n",
    "**Image → LLM Extraction → Multi-Agent Validation → JSON (corrected ODEs + concepts) → Template Model → Mtx odes**\n",
    "\n",
    "**REMAINING ERRORS:**\n",
    "- Parameter consistency: mostly symbolic differences (e.g. rho_1 vs. rho1), sometimes more serious: e.g. rho vs. q (similar) -> LLM has no info, which one is used, doesn’t know it needs fix\n",
    "- Multiplication vs. addition still gets mixed up sometimes\n",
    "- Semantic compartment mismatches I(t) vs. T(t)-> extra validation needed e.g. linear and \n",
    "- Strengthening of the arithmetic validation is much needed!\n",
    "- Precision of coefficient extraction \n",
    "- Still remains: CodeExecutionError: Error while executing the code: 'Symbol' object is not callable (examples: BIOMD000000972, BIOMD000000976)\n",
    "- The error handling function  mixes up the order of operations in some cases (example: BIOMD0000000991)\n",
    "- Extraction of the compartments differ from the original completely, maybe derived from the RHS (example: 2024_dec_epi_1_model_A)\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "> CURRENT VERSION:\n",
    "## Multi-Agent Pipeline:\n",
    "**version= 003**\n",
    "\n",
    "There are clearly separable problem areas, which will be better managed by breaking down the agent architecture into more steps. \n",
    "\n",
    "A mulit-agenda based approach will systematically address extraction challenges by organizing the process into distinct agenda items, each targeting specific aspects of the process:\n",
    "\n",
    "## Phase 1: ODE Extraction (`ODEExtractionSpecialist`)\n",
    "- Initial extraction as in version 001\n",
    "- Extraction is integrated into the pipeline to ensure conservation of all information during the initial first step\n",
    "\n",
    "## Phase 2: Concept Grounding (`ConceptGrounder`)\n",
    "- Regular expression pattern matching to extract ODE definitions\n",
    "- Semantic analysis of variable names and contexts\n",
    "- Generation of concept_data dictionary with biological/epidemiological annotations (the same way as in version 001)\n",
    "\n",
    "## Phase 3: Execution Error Correction (`ExecutionErrorCorrector`)\n",
    "- Iterative workflow for finding and correcting execution errors\n",
    "- Automated fixes for:\n",
    "  - Missing imports (sympy modules)\n",
    "  - Undefined symbols/functions\n",
    "  - Namespace conflicts\n",
    "  - Syntax errors\n",
    "\n",
    "## Phase 4: Dual Validation (`ValidationAggregator` + `MathematicalAggregator`)\n",
    "**ValidationAggregator:**\n",
    "- Parameter consistency checking\n",
    "- Time-dependency classification\n",
    "- Symbol usage validation\n",
    "\n",
    "**MathematicalAggregator:**\n",
    "- Dimensional analysis\n",
    "- Conservation law verification\n",
    "- Mathematical structure validation\n",
    "\n",
    "## Phase 5: Unified Error Correction (`UnifiedErrorCorrector`)\n",
    "- Comprehensive error analysis from all previous phases\n",
    "- Prioritized correction strategy\n",
    "- Fixes for:\n",
    "  - Symbol/Function type mismatches\n",
    "  - Missing transmission terms (e.g., /N)\n",
    "  - Parameter definition inconsistencies\n",
    "  - Equation completeness issues\n",
    "\n",
    "## Phase 6: Quantitative Evaluation (`QuantitativeEvaluator`)\n",
    "- Load correct equations from manually pre-made TSV file\n",
    "- String normalization and comparison\n",
    "- Calculation of metrics:\n",
    "  - **Execution Success Rate:** Binary pass/fail\n",
    "  - **Equation Accuracy Rate:** Percentage of matching equations\n",
    "  - **Detailed comparison:** Per-equation match status\n",
    "- **Quantitative measures are implemented to replace manual ODE comparison, providing automated accuracy assessment**\n",
    "\n",
    "## Post-Pipeline Processing:\n",
    "**After the pipeline completes, the system creates a TemplateModel** using the validated ODEs and grounded concepts.\n",
    "\n",
    "This pipeline transforms the single-shot extraction into a robust, multi-step process where each agent specializes in one aspect of validation and correction. \n",
    "\n",
    "Since each agent requires a distinct approach and prompt configuration, the LLM can achieve better focus (rather than receiving a summarized, less detailed message).\n",
    "\n",
    "### Other possible agenda items:\n",
    "\n",
    "6. Symbol Validation – Are all variables and parameters defined? this focuses more on JSON\n",
    "\n",
    "7. Biological Context Tagging – Are compartments semantically labeled (e.g., S = susceptible)?\n",
    "\n",
    "8. JSON Structure Integrity – Is the output JSON consistent and complete?\n",
    "\n",
    "---\n",
    "\n",
    "> NEXT STEPS:\n",
    "\n",
    "- **Initial conditions extraction:** Automatically identify and extract initial values for state variables from source documents\n",
    "- **Parameter information extraction:** Mine the full article for parameter values, units, and contextual descriptions\n",
    "- **Scaling the method:** Extend the pipeline to handle larger document sets and batch processing of multiple biomodels\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
