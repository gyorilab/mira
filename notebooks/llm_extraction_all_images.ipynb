{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "403450bd",
   "metadata": {},
   "source": [
    "Preparations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2141c5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check API key\n",
    "# import os\n",
    "\n",
    "# api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "# if api_key:\n",
    "#     print(\"API key is set\")\n",
    "# else:\n",
    "#     print(\"API key not found in environment variables\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c28d24a0-175a-45cd-8d17-34d028820d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mira.openai import OpenAIClient\n",
    "from mira.sources.sympy_ode.llm_util import execute_template_model_from_sympy_odes, image_file_to_odes_str\n",
    "client = OpenAIClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6069445b-a504-4b88-8468-e8a172609000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 24 files to process:\n",
      "  - BIOMD0000000972.png\n",
      "  - BIOMD0000000964.png\n",
      "  - BIOMD0000000970.png\n",
      "  - BIOMD0000000958.png\n",
      "  - BIOMD0000000971.png\n",
      "  - BIOMD0000000974.png\n",
      "  - BIOMD0000000960.png\n",
      "  - BIOMD0000000976.png\n",
      "  - BIOMD0000000962.png\n",
      "  - SAPHIRE.png\n",
      "  - BIOMD0000000963.png\n",
      "  - BIOMD0000000977.png\n",
      "  - 2024_dec_epi_1_model_C.png\n",
      "  - 2024_dec_epi_1_model_B.png\n",
      "  - odes_to_mira_SEVITHR.png\n",
      "  - 2024_dec_epi_1_model_A.png\n",
      "  - BIOMD0000000991.png\n",
      "  - BIOMD0000000984.png\n",
      "  - BIOMD0000000979.png\n",
      "  - BIOMD0000000978.png\n",
      "  - BIOMD0000000983.png\n",
      "  - BIOMD0000000955.png\n",
      "  - BIOMD0000000957.png\n",
      "  - BIOMD0000000956.png\n",
      "\n",
      "Processing: BIOMD0000000972.png\n",
      "\n",
      "Processing: BIOMD0000000964.png\n",
      "\n",
      "Processing: BIOMD0000000970.png\n",
      "\n",
      "Processing: BIOMD0000000958.png\n",
      "\n",
      "Processing: BIOMD0000000971.png\n",
      "\n",
      "Processing: BIOMD0000000974.png\n",
      "\n",
      "Processing: BIOMD0000000960.png\n",
      "\n",
      "Processing: BIOMD0000000976.png\n",
      "\n",
      "Processing: BIOMD0000000962.png\n",
      "\n",
      "Processing: SAPHIRE.png\n",
      "\n",
      "Processing: BIOMD0000000963.png\n",
      "\n",
      "Processing: BIOMD0000000977.png\n",
      "\n",
      "Processing: 2024_dec_epi_1_model_C.png\n",
      "\n",
      "Processing: 2024_dec_epi_1_model_B.png\n",
      "\n",
      "Processing: odes_to_mira_SEVITHR.png\n",
      "\n",
      "Processing: 2024_dec_epi_1_model_A.png\n",
      "\n",
      "Processing: BIOMD0000000991.png\n",
      "\n",
      "Processing: BIOMD0000000984.png\n",
      "\n",
      "Processing: BIOMD0000000979.png\n",
      "\n",
      "Processing: BIOMD0000000978.png\n",
      "\n",
      "Processing: BIOMD0000000983.png\n",
      "\n",
      "Processing: BIOMD0000000955.png\n",
      "\n",
      "Processing: BIOMD0000000957.png\n",
      "\n",
      "Processing: BIOMD0000000956.png\n"
     ]
    }
   ],
   "source": [
    "# Extract ODEs from images\n",
    "import os\n",
    "from IPython.display import Image, display\n",
    "\n",
    "image_folder = './images'  \n",
    "\n",
    "image_files = [f for f in os.listdir(image_folder) if not f.startswith('.')] # images that do not start with a dot in their file name\n",
    "\n",
    "print(f\"Found {len(image_files)} files to process:\")\n",
    "for img_file in image_files:\n",
    "    print(f\"  - {img_file}\")\n",
    "\n",
    "for image_file in image_files:\n",
    "    image_path = os.path.join(image_folder, image_file)\n",
    "    print(f\"\\nProcessing: {image_file}\")\n",
    "    #display(Image(image_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f49b183-d6fe-4489-9008-04db2c0d8ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for one image only:\n",
    "# ode_str = image_file_to_odes_str(image_path, client=client)\n",
    "# print(ode_str)\n",
    "\n",
    "# Note that the LLM sometimes misses to define one of the parameters. When this happens, a human-in-the-loop can quickly edit the output:\n",
    "\n",
    "# Cleaned version of string above, uncomment to use it\n",
    "# ode_str = \"\"\"import sympy\n",
    "\n",
    "# # Define time variable\n",
    "# t = sympy.symbols(\"t\")\n",
    "\n",
    "# # Define the time-dependent variables\n",
    "# S, E, I, T, R, V, H = sympy.symbols(\"S E I T R V H\", cls=sympy.Function)\n",
    "\n",
    "# # Define the parameters\n",
    "# lambda_, epsilon_v, p_T, delta, eta, kappa, mu, sigma = sympy.symbols(\"lambda_ epsilon_v p_T delta eta kappa mu sigma\")\n",
    "\n",
    "# odes = [\n",
    "#    sympy.Eq(S(t).diff(t), - lambda_ * S(t)),\n",
    "#    sympy.Eq(E(t).diff(t), lambda_ * S(t) + (1 - epsilon_v) * lambda_ * V(t) - sigma * E(t)),\n",
    "#    sympy.Eq(I(t).diff(t), (1 - p_T) * sigma * E(t) - (delta + eta) * I(t)),\n",
    "#    sympy.Eq(T(t).diff(t), p_T * sigma * E(t) - delta * T(t)),\n",
    "#    sympy.Eq(R(t).diff(t), delta * I(t) + delta * T(t) + kappa * H(t)),\n",
    "#    sympy.Eq(V(t).diff(t), - (1 - epsilon_v) * lambda_ * V(t)),\n",
    "#    sympy.Eq(H(t).diff(t), eta * I(t) - (kappa + mu) * H(t))\n",
    "#     ]\"\"\"\n",
    "\n",
    "# print(ode_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "563064b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Processing: BIOMD0000000972.png\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: [2025-08-28 09:45:27] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO: [2025-08-28 09:45:27] openai._base_client - Retrying request to /chat/completions in 0.436000 seconds\n",
      "INFO: [2025-08-28 09:45:28] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO: [2025-08-28 09:45:28] openai._base_client - Retrying request to /chat/completions in 0.979354 seconds\n",
      "INFO: [2025-08-28 09:45:30] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✗ Failed to process BIOMD0000000972.png: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "\n",
      "============================================================\n",
      "Processing: BIOMD0000000964.png\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: [2025-08-28 09:45:32] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO: [2025-08-28 09:45:32] openai._base_client - Retrying request to /chat/completions in 0.392887 seconds\n",
      "INFO: [2025-08-28 09:45:33] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO: [2025-08-28 09:45:33] openai._base_client - Retrying request to /chat/completions in 0.762555 seconds\n",
      "INFO: [2025-08-28 09:45:34] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO: [2025-08-28 09:45:34] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO: [2025-08-28 09:45:34] openai._base_client - Retrying request to /chat/completions in 0.403731 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✗ Failed to process BIOMD0000000964.png: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "\n",
      "============================================================\n",
      "Processing: BIOMD0000000970.png\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: [2025-08-28 09:45:35] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO: [2025-08-28 09:45:35] openai._base_client - Retrying request to /chat/completions in 0.914735 seconds\n",
      "INFO: [2025-08-28 09:45:37] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO: [2025-08-28 09:45:37] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO: [2025-08-28 09:45:37] openai._base_client - Retrying request to /chat/completions in 0.458159 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✗ Failed to process BIOMD0000000970.png: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "\n",
      "============================================================\n",
      "Processing: BIOMD0000000958.png\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: [2025-08-28 09:45:37] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO: [2025-08-28 09:45:37] openai._base_client - Retrying request to /chat/completions in 0.937036 seconds\n",
      "INFO: [2025-08-28 09:45:39] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO: [2025-08-28 09:45:39] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO: [2025-08-28 09:45:39] openai._base_client - Retrying request to /chat/completions in 0.444477 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✗ Failed to process BIOMD0000000958.png: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "\n",
      "============================================================\n",
      "Processing: BIOMD0000000971.png\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: [2025-08-28 09:45:40] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO: [2025-08-28 09:45:40] openai._base_client - Retrying request to /chat/completions in 0.750967 seconds\n",
      "INFO: [2025-08-28 09:45:40] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO: [2025-08-28 09:45:41] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO: [2025-08-28 09:45:41] openai._base_client - Retrying request to /chat/completions in 0.492422 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✗ Failed to process BIOMD0000000971.png: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "\n",
      "============================================================\n",
      "Processing: BIOMD0000000974.png\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: [2025-08-28 09:45:41] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO: [2025-08-28 09:45:41] openai._base_client - Retrying request to /chat/completions in 0.792475 seconds\n",
      "INFO: [2025-08-28 09:45:42] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO: [2025-08-28 09:45:42] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO: [2025-08-28 09:45:42] openai._base_client - Retrying request to /chat/completions in 0.394915 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✗ Failed to process BIOMD0000000974.png: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "\n",
      "============================================================\n",
      "Processing: BIOMD0000000960.png\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: [2025-08-28 09:45:43] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO: [2025-08-28 09:45:43] openai._base_client - Retrying request to /chat/completions in 0.914619 seconds\n",
      "INFO: [2025-08-28 09:45:44] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO: [2025-08-28 09:45:44] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO: [2025-08-28 09:45:44] openai._base_client - Retrying request to /chat/completions in 0.376057 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✗ Failed to process BIOMD0000000960.png: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "\n",
      "============================================================\n",
      "Processing: BIOMD0000000976.png\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: [2025-08-28 09:45:45] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO: [2025-08-28 09:45:45] openai._base_client - Retrying request to /chat/completions in 0.923727 seconds\n",
      "INFO: [2025-08-28 09:45:46] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO: [2025-08-28 09:45:46] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO: [2025-08-28 09:45:46] openai._base_client - Retrying request to /chat/completions in 0.422896 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✗ Failed to process BIOMD0000000976.png: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "\n",
      "============================================================\n",
      "Processing: BIOMD0000000962.png\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: [2025-08-28 09:45:46] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO: [2025-08-28 09:45:46] openai._base_client - Retrying request to /chat/completions in 0.794913 seconds\n",
      "INFO: [2025-08-28 09:45:47] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO: [2025-08-28 09:45:47] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO: [2025-08-28 09:45:47] openai._base_client - Retrying request to /chat/completions in 0.495723 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✗ Failed to process BIOMD0000000962.png: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "\n",
      "============================================================\n",
      "Processing: SAPHIRE.png\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: [2025-08-28 09:45:48] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO: [2025-08-28 09:45:48] openai._base_client - Retrying request to /chat/completions in 0.928233 seconds\n",
      "INFO: [2025-08-28 09:45:49] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO: [2025-08-28 09:45:49] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO: [2025-08-28 09:45:49] openai._base_client - Retrying request to /chat/completions in 0.375224 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✗ Failed to process SAPHIRE.png: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "\n",
      "============================================================\n",
      "Processing: BIOMD0000000963.png\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: [2025-08-28 09:45:50] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO: [2025-08-28 09:45:50] openai._base_client - Retrying request to /chat/completions in 0.841710 seconds\n",
      "INFO: [2025-08-28 09:45:51] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO: [2025-08-28 09:45:51] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO: [2025-08-28 09:45:51] openai._base_client - Retrying request to /chat/completions in 0.379271 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✗ Failed to process BIOMD0000000963.png: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "\n",
      "============================================================\n",
      "Processing: BIOMD0000000977.png\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: [2025-08-28 09:45:51] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO: [2025-08-28 09:45:51] openai._base_client - Retrying request to /chat/completions in 0.999231 seconds\n",
      "INFO: [2025-08-28 09:45:52] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO: [2025-08-28 09:45:52] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO: [2025-08-28 09:45:52] openai._base_client - Retrying request to /chat/completions in 0.473618 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✗ Failed to process BIOMD0000000977.png: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "\n",
      "============================================================\n",
      "Processing: 2024_dec_epi_1_model_C.png\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: [2025-08-28 09:45:53] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO: [2025-08-28 09:45:53] openai._base_client - Retrying request to /chat/completions in 0.785179 seconds\n",
      "INFO: [2025-08-28 09:45:54] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO: [2025-08-28 09:45:54] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO: [2025-08-28 09:45:54] openai._base_client - Retrying request to /chat/completions in 0.387516 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✗ Failed to process 2024_dec_epi_1_model_C.png: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "\n",
      "============================================================\n",
      "Processing: 2024_dec_epi_1_model_B.png\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: [2025-08-28 09:45:54] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO: [2025-08-28 09:45:54] openai._base_client - Retrying request to /chat/completions in 0.843167 seconds\n",
      "INFO: [2025-08-28 09:45:55] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO: [2025-08-28 09:45:55] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO: [2025-08-28 09:45:55] openai._base_client - Retrying request to /chat/completions in 0.431289 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✗ Failed to process 2024_dec_epi_1_model_B.png: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "\n",
      "============================================================\n",
      "Processing: odes_to_mira_SEVITHR.png\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: [2025-08-28 09:45:56] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO: [2025-08-28 09:45:56] openai._base_client - Retrying request to /chat/completions in 0.967208 seconds\n",
      "INFO: [2025-08-28 09:45:57] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO: [2025-08-28 09:45:57] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO: [2025-08-28 09:45:57] openai._base_client - Retrying request to /chat/completions in 0.430820 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✗ Failed to process odes_to_mira_SEVITHR.png: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "\n",
      "============================================================\n",
      "Processing: 2024_dec_epi_1_model_A.png\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: [2025-08-28 09:45:58] httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO: [2025-08-28 09:45:58] openai._base_client - Retrying request to /chat/completions in 0.791499 seconds\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mHTTPStatusError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/mira/.venv/lib/python3.13/site-packages/openai/_base_client.py:1027\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1026\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1027\u001b[39m     \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1028\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m httpx.HTTPStatusError \u001b[38;5;28;01mas\u001b[39;00m err:  \u001b[38;5;66;03m# thrown on 4xx and 5xx status code\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/mira/.venv/lib/python3.13/site-packages/httpx/_models.py:829\u001b[39m, in \u001b[36mResponse.raise_for_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    828\u001b[39m message = message.format(\u001b[38;5;28mself\u001b[39m, error_type=error_type)\n\u001b[32m--> \u001b[39m\u001b[32m829\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m HTTPStatusError(message, request=request, response=\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[31mHTTPStatusError\u001b[39m: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'\nFor more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m=\u001b[39m\u001b[33m'\u001b[39m*\u001b[32m60\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:        \n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m     ode_str = \u001b[43mimage_file_to_odes_str\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclient\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mExtracted odes:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     15\u001b[39m     \u001b[38;5;28mprint\u001b[39m(ode_str[:\u001b[32m500\u001b[39m])  \n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/mira/mira/sources/sympy_ode/llm_util.py:44\u001b[39m, in \u001b[36mimage_file_to_odes_str\u001b[39m\u001b[34m(image_path, client)\u001b[39m\n\u001b[32m     42\u001b[39m     image_bytes = f.read()\n\u001b[32m     43\u001b[39m image_format = image_path.split(\u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m)[-\u001b[32m1\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m44\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimage_to_odes_str\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_bytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_format\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/mira/mira/sources/sympy_ode/llm_util.py:70\u001b[39m, in \u001b[36mimage_to_odes_str\u001b[39m\u001b[34m(image_bytes, client, image_format)\u001b[39m\n\u001b[32m     52\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Get an ODE string from an image depicting an ODE system\u001b[39;00m\n\u001b[32m     53\u001b[39m \n\u001b[32m     54\u001b[39m \u001b[33;03mParameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     67\u001b[39m \u001b[33;03m    necessary to define the ODEs using sympy.\u001b[39;00m\n\u001b[32m     68\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     69\u001b[39m base64_image = base64.b64encode(image_bytes).decode(\u001b[33m'\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m70\u001b[39m response = \u001b[43mextract_ode_str_from_base64_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase64_image\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbase64_image\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m                                             \u001b[49m\u001b[43mimage_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43mimage_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m                                             \u001b[49m\u001b[43mclient\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/mira/mira/sources/sympy_ode/llm_util.py:125\u001b[39m, in \u001b[36mextract_ode_str_from_base64_image\u001b[39m\u001b[34m(base64_image, image_format, client, prompt)\u001b[39m\n\u001b[32m    122\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m prompt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    123\u001b[39m     prompt = ODE_IMAGE_PROMPT\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m choice = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_chat_completion_with_image\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    126\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    127\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbase64_image\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbase64_image\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    128\u001b[39m \u001b[43m    \u001b[49m\u001b[43mimage_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43mimage_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    129\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    130\u001b[39m text_response = clean_response(choice.message.content)\n\u001b[32m    131\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m text_response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/mira/mira/openai/client.py:94\u001b[39m, in \u001b[36mOpenAIClient.run_chat_completion_with_image\u001b[39m\u001b[34m(self, message, base64_image, model, image_format, max_tokens)\u001b[39m\n\u001b[32m     89\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m image_format \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ALLOWED_FORMATS:\n\u001b[32m     90\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m     91\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mImage format \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimage_format\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not supported.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     92\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSupported formats are \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mALLOWED_FORMATS\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     93\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchat\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompletions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     95\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     96\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m     97\u001b[39m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m     98\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrole\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     99\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m    100\u001b[39m \u001b[43m                \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    101\u001b[39m \u001b[43m                    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtype\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtext\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    102\u001b[39m \u001b[43m                    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtext\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    103\u001b[39m \u001b[43m                \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    104\u001b[39m \u001b[43m                \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    105\u001b[39m \u001b[43m                    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtype\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mimage_url\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    106\u001b[39m \u001b[43m                    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mimage_url\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    107\u001b[39m \u001b[43m                        \u001b[49m\u001b[38;5;66;43;03m# Supports PNG, JPEG, WEBP, non-animated GIF\u001b[39;49;00m\n\u001b[32m    108\u001b[39m \u001b[43m                        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43murl\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdata:image/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mimage_format\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m;base64,\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mbase64_image\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m    109\u001b[39m \u001b[43m                    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    110\u001b[39m \u001b[43m                \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    111\u001b[39m \u001b[43m            \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    112\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\n\u001b[32m    113\u001b[39m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    114\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    115\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response.choices[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/mira/.venv/lib/python3.13/site-packages/openai/_utils/_utils.py:287\u001b[39m, in \u001b[36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    285\u001b[39m             msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[32m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    286\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m287\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/mira/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py:1135\u001b[39m, in \u001b[36mCompletions.create\u001b[39m\u001b[34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, reasoning_effort, response_format, safety_identifier, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m   1090\u001b[39m \u001b[38;5;129m@required_args\u001b[39m([\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m], [\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m   1091\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m   1092\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1132\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = NOT_GIVEN,\n\u001b[32m   1133\u001b[39m ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[32m   1134\u001b[39m     validate_response_format(response_format)\n\u001b[32m-> \u001b[39m\u001b[32m1135\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1136\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1137\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1138\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m   1139\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1140\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1141\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maudio\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1142\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1143\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1144\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1145\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1146\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1147\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1148\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1149\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1150\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodalities\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1151\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1152\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1153\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprediction\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1154\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1155\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt_cache_key\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_cache_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1156\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_effort\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1157\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1158\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msafety_identifier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msafety_identifier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1159\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1160\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1161\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1162\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1163\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1164\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1165\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1166\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1167\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1168\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1169\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1170\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1171\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweb_search_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1172\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1173\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsStreaming\u001b[49m\n\u001b[32m   1174\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[32m   1175\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1176\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1177\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1178\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m   1179\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1180\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1181\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/mira/.venv/lib/python3.13/site-packages/openai/_base_client.py:1259\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1245\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1246\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1247\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1254\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1255\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1256\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1257\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1258\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1259\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/mira/.venv/lib/python3.13/site-packages/openai/_base_client.py:1033\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1031\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m remaining_retries > \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._should_retry(err.response):\n\u001b[32m   1032\u001b[39m     err.response.close()\n\u001b[32m-> \u001b[39m\u001b[32m1033\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sleep_for_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1034\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1035\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1036\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1037\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1038\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1039\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1041\u001b[39m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[32m   1042\u001b[39m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/mira/.venv/lib/python3.13/site-packages/openai/_base_client.py:1073\u001b[39m, in \u001b[36mSyncAPIClient._sleep_for_retry\u001b[39m\u001b[34m(self, retries_taken, max_retries, options, response)\u001b[39m\n\u001b[32m   1070\u001b[39m timeout = \u001b[38;5;28mself\u001b[39m._calculate_retry_timeout(remaining_retries, options, response.headers \u001b[38;5;28;01mif\u001b[39;00m response \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m   1071\u001b[39m log.info(\u001b[33m\"\u001b[39m\u001b[33mRetrying request to \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m in \u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[33m seconds\u001b[39m\u001b[33m\"\u001b[39m, options.url, timeout)\n\u001b[32m-> \u001b[39m\u001b[32m1073\u001b[39m \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# for multiple images:\n",
    "\n",
    "all_results = []\n",
    "failed_extractions = []\n",
    "\n",
    "for image_file in image_files:\n",
    "    image_path = os.path.join(image_folder, image_file)\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Processing: {image_file}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    try:        \n",
    "        ode_str = image_file_to_odes_str(image_path, client)\n",
    "        print(\"Extracted odes:\")\n",
    "        print(ode_str[:500])  \n",
    "        \n",
    "        template_model = execute_template_model_from_sympy_odes(\n",
    "            ode_str=ode_str,\n",
    "            attempt_grounding=True,\n",
    "            client=client,\n",
    "            use_multi_agent=True,\n",
    "            max_correction_iterations=3\n",
    "        )\n",
    "        \n",
    "        concepts_map = template_model.get_concepts_map()\n",
    "        \n",
    "        result = {\n",
    "            'image_file': image_file,\n",
    "            'template_model': template_model,\n",
    "            'status': 'success'\n",
    "        }\n",
    "        all_results.append(result)\n",
    "        \n",
    "        print(f\"Successfully extracted from {image_file}\")\n",
    "        print(f\"  - Templates: {len(template_model.templates)}\")\n",
    "        print(f\"  - Concepts: {len(concepts_map)}\")\n",
    "        print(f\"  - Parameters: {len(template_model.parameters)}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"✗ Failed to process {image_file}: {str(e)}\")\n",
    "        failed_extractions.append({\n",
    "            'image_file': image_file,\n",
    "            'error': str(e),\n",
    "            'status': 'failed'\n",
    "        })\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"PROCESSING SUMMARY\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Total files: {len(image_files)}\")\n",
    "print(f\"Successful extractions: {len(all_results)}\")\n",
    "print(f\"Failed extractions: {len(failed_extractions)}\")\n",
    "\n",
    "if failed_extractions:\n",
    "    print(f\"\\nFailed files:\")\n",
    "    for failure in failed_extractions:\n",
    "        print(f\"  - {failure['image_file']}: {failure['error']}\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2883601f-f85d-4c6f-8018-0ee2ca34c3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for one image only:\n",
    "# Now get a template model from the extracted ODE str and send the ODE system in for attempting to ground each compartment\n",
    "#from mira.sources.sympy_ode.llm_util import execute_template_model_from_sympy_odes\n",
    "\n",
    "#tm = execute_template_model_from_sympy_odes(ode_str=ode_str, attempt_grounding=True, client=client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd210de1-c2c4-4b21-8ffc-7b446d80e213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for one image:\n",
    "# Check the concepts\n",
    "# print('concept name\\tidentifiers\\tcontext')\n",
    "# for concept in tm.get_concepts_map().values():\n",
    "#     print(f'{concept.name}\\t{concept.identifiers}\\t{concept.context}')\n",
    "\n",
    "# for all images:\n",
    "for result in all_results:\n",
    "    tm = result['template_model']\n",
    "    image_file = result['image_file']\n",
    "    \n",
    "    print(f\"\\n=== Concepts from {image_file} ===\")\n",
    "    concepts_map = tm.get_concepts_map()\n",
    "    \n",
    "    if concepts_map:\n",
    "        print('concept name\\tidentifiers\\tcontext')\n",
    "        for concept in concepts_map.values():\n",
    "            print(f'{concept.name}\\t{concept.identifiers}\\t{concept.context}')\n",
    "    else:\n",
    "        print(\"No concepts found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d1ffe5-6792-4b63-8fd7-e5477efc9f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from mira.modeling import Model\n",
    "# from mira.modeling.ode import OdeModel\n",
    "# om = OdeModel(Model(tm), initialized=True)\n",
    "# om.get_interpretable_kinetics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a4870d",
   "metadata": {},
   "source": [
    "Above: let's save the results here: *mira/notebooks/equation extraction development/extraction error check/string mismatch check/extracted_eqs_all versions_EXCEL.xlsx*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59373727",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa419dd7",
   "metadata": {},
   "source": [
    "let's add a variable \"version\" to see, which version of the AI architecture are we using at the moment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f0df3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "version = '002' # this is the 2-step iterative architecture but change the number to a different one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd3282d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_all_ode_results_with_strings(all_results, failed_extractions, version=\"002\"):\n",
    "    \"\"\"Save actual ODE strings for all images\"\"\"\n",
    "    \n",
    "    excel_path = './equation extraction development/extraction error check/string mismatch check/extracted_eqs_all versions_EXCEL.xlsx'\n",
    "    version_col = f'version{version}'\n",
    "    \n",
    "    try:\n",
    "        df = pd.read_excel(excel_path, engine='openpyxl')\n",
    "    except FileNotFoundError:\n",
    "        df = pd.DataFrame(columns=['model', version_col]) \n",
    "    \n",
    "    # Process successful results - extract ONLY the odes part\n",
    "    for result in all_results:\n",
    "        model_name = Path(result['image_file']).stem\n",
    "        full_ode_str = result.get('ode_str', '')\n",
    "        \n",
    "        # Extract only the odes = [...] part\n",
    "        if full_ode_str:\n",
    "            start = full_ode_str.find('odes = [')\n",
    "            end = full_ode_str.find(']', start) + 1\n",
    "            \n",
    "            if start != -1 and end != 0:\n",
    "                ode_str_clean = full_ode_str[start:end]\n",
    "            else:\n",
    "                ode_str_clean = \"No 'odes = [...]' pattern found\"\n",
    "        else:\n",
    "            ode_str_clean = 'SUCCESS - No ODE string stored'\n",
    "        \n",
    "        # Update or add row\n",
    "        if 'model' in df.columns and not df.empty:\n",
    "            model_exists = df['model'] == model_name\n",
    "            if model_exists.any():\n",
    "                df.loc[model_exists, version_col] = ode_str_clean\n",
    "            else:\n",
    "                new_row = pd.DataFrame({'model': [model_name], version_col: [ode_str_clean]})\n",
    "                df = pd.concat([df, new_row], ignore_index=True)\n",
    "        else:\n",
    "            df = pd.DataFrame({'model': [model_name], version_col: [ode_str_clean]})\n",
    "    \n",
    "    # Process failures\n",
    "    for failure in failed_extractions:\n",
    "        model_name = Path(failure['image_file']).stem\n",
    "        error_msg = f\"FAILED: {failure['error'][:100]}...\"\n",
    "        \n",
    "        if 'model' in df.columns and not df.empty:\n",
    "            model_exists = df['model'] == model_name\n",
    "            if model_exists.any():\n",
    "                df.loc[model_exists, version_col] = error_msg\n",
    "            else:\n",
    "                new_row = pd.DataFrame({'model': [model_name], version_col: [error_msg]})\n",
    "                df = pd.concat([df, new_row], ignore_index=True)\n",
    "        else:\n",
    "            df = pd.DataFrame({'model': [model_name], version_col: [error_msg]})\n",
    "    \n",
    "    df.to_excel(excel_path, index=False, engine='openpyxl')\n",
    "    print(f\"Saved clean ODE strings for {len(all_results)} successful and {len(failed_extractions)} failed extractions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292f27fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def save_ode_results(ode_str, input_filename):\n",
    "#     \"\"\"\n",
    "#     Save ODE extraction results to Excel file.\n",
    "    \n",
    "#     Parameters:\n",
    "#     -----------\n",
    "#     ode_str : str\n",
    "#         The extracted ODEs from MIRA\n",
    "#     input_filename : str\n",
    "#         The input file name (e.g., 'model_name.png')\n",
    "#     \"\"\"\n",
    "\n",
    "#     excel_path = './equation extraction development/extraction error check/string mismatch check/extracted_eqs_all versions_EXCEL.xlsx'\n",
    "#     model_name = Path(input_filename).stem\n",
    "\n",
    "#     try:\n",
    "#         df = pd.read_excel(excel_path, engine='openpyxl')\n",
    "#     except FileNotFoundError:\n",
    "#         df = pd.DataFrame(columns=['model', 'version{version}']) \n",
    "\n",
    "#     if 'model' in df.columns:\n",
    "#         model_exists = df['model'] == model_name\n",
    "\n",
    "#         if model_exists.any():\n",
    "#             df.loc[model_exists, 'version002'] = ode_str\n",
    "#         else:\n",
    "#             new_row = pd.DataFrame({\n",
    "#                 'model': [model_name],\n",
    "#                 'version002': [ode_str]\n",
    "#             })\n",
    "#             df = pd.concat([df, new_row], ignore_index=True)\n",
    "#     else:\n",
    "#         df['model'] = model_name\n",
    "#         df['version{version}'] = ode_str\n",
    "\n",
    "#     df.to_excel(excel_path, index=False, engine='openpyxl')\n",
    "#     print(f\"Saved equations for model '{model_name}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070b99eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for one image only:\n",
    "# start = ode_str.find('odes = [')\n",
    "# end = ode_str.find(']', start) + 1\n",
    "# ode_str_clean = ode_str[start:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340064bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved clean ODE strings for 0 successful and 24 failed extractions\n"
     ]
    }
   ],
   "source": [
    "#for one image:\n",
    "# save_ode_results(ode_str_clean, image_path)\n",
    "\n",
    "# for all images:\n",
    "save_all_ode_results_with_strings(all_results, failed_extractions, version=\"002\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3510f3d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TSV file saved: ./equation extraction development/extraction error check/string mismatch check/extracted_eqs_VERSION002.tsv\n"
     ]
    }
   ],
   "source": [
    "def create_tsv_from_excel(version='002'):\n",
    "    \n",
    "    excel_path = './equation extraction development/extraction error check/string mismatch check/extracted_eqs_all versions_EXCEL.xlsx'\n",
    "    df = pd.read_excel(excel_path, engine='openpyxl')\n",
    "    \n",
    "    tsv_df = pd.DataFrame({\n",
    "        'model': df['model'],\n",
    "        'extracted_eqs': df[f'version{version}']\n",
    "    })\n",
    "    \n",
    "    tsv_df = tsv_df.dropna(subset=['extracted_eqs'])\n",
    "    \n",
    "    tsv_path = f'./equation extraction development/extraction error check/string mismatch check/extracted_eqs_VERSION{version}.tsv'\n",
    "    tsv_df.to_csv(tsv_path, sep='\\t', index=False)\n",
    "    print(f\"TSV file saved: {tsv_path}\")\n",
    "\n",
    "create_tsv_from_excel(version)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mira)",
   "language": "python",
   "name": "mira"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
