{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ad3652d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#features\n",
    "import re\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "#comparison\n",
    "import json\n",
    "#LLM\n",
    "from openai import OpenAI\n",
    "import os\n",
    "import time\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d5f95c7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API key loaded successfully\n"
     ]
    }
   ],
   "source": [
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "# verifying the setup\n",
    "if os.getenv(\"OPENAI_API_KEY\"):\n",
    "    print(\"OpenAI API key loaded successfully\")\n",
    "else:\n",
    "    print(\"Error: OPENAI_API_KEY not found in .env file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe08aac4",
   "metadata": {},
   "source": [
    "### Error analysis and validation for MIRA equations extraction\n",
    "\n",
    "This project develops pipeline to automatically analyse the extraction method of equations by MIRA, focusing specifically on correctness errors. These errors can include both equation components (variables, parameters etc.) and their graphical representations in source articles, which are analyzed through detailed feature engineering. The workflow integrates analysis of the used symbols, mathematical validation and visual features to assess MIRA's extraction quality.\n",
    "\n",
    "Key steps:\n",
    "- Data extraction: original sources (correct equations) and results of the extraction process (extracted equations)\n",
    "- Defining all the possible features ODEs can have\n",
    "- Comparing ODE systems in 3 steps:\n",
    "    1. identifying the symbolic, mathematical and graphic features of the original equations and calculating complexty metrics\n",
    "    1. comparing the extracted equations to the original equations (model specific) \n",
    "    2. categorizing or labeling the appearing errors\n",
    "- Finding the connection between the features of the equations and the appearing error types (correlation, odds ratios, test values etc.)\n",
    "\n",
    "- Evaluation of the trained model for development purposes: Performance is measured using cross-validation and robustness testing\n",
    "\n",
    "An example of a possible outcome: 89% of the models, where equations contain the greek letter 'alpha' have a symbol detection problem not recognizing the subscript parts of the alpha symbols - conclusion: prompting should be improved focusing on greek letters with sub- or superscripts\n",
    "\n",
    "Once the error analysis system is successfully completed, it could potentially be integrated into MIRA's final diagnostic step (the last agent item), enabling the LLM to perform automatic correctness evaluations as part of the extraction process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3b3f48",
   "metadata": {},
   "source": [
    "Let's start with importing the original equations and the extracted version of the models:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d17d15",
   "metadata": {},
   "source": [
    "#### Configurating the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7507599a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration loaded:\n",
      "- OpenAI Model: gpt-4\n",
      "- Version: 001\n",
      "- Output Directory: .\n"
     ]
    }
   ],
   "source": [
    "# OpenAI Configuration\n",
    "OPENAI_MODEL = \"gpt-4\"\n",
    "TEMPERATURE = 0.0\n",
    "MAX_TOKENS = 1024\n",
    "\n",
    "# Analysis Configuration\n",
    "VERSION = '001'  # Version to analyze from extracted equations\n",
    "SAVE_RESULTS = True \n",
    "\n",
    "# Output file names\n",
    "OUTPUT_DIR = '.'  # current directory, change if needed\n",
    "FEATURES_OUTPUT = f'{OUTPUT_DIR}/features_analysis_{VERSION}.csv'\n",
    "SUMMARY_OUTPUT = f'{OUTPUT_DIR}/error_analysis_summary_{VERSION}.csv'\n",
    "COMPARISON_OUTPUT = f'{OUTPUT_DIR}/comparison_results_{VERSION}.json'\n",
    "CATEGORIZATION_OUTPUT = f'{OUTPUT_DIR}/categorization_results_{VERSION}.json'\n",
    "\n",
    "print(\"Configuration loaded:\")\n",
    "print(f\"- OpenAI Model: {OPENAI_MODEL}\")\n",
    "print(f\"- Version: {VERSION}\")\n",
    "print(f\"- Output Directory: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51cb1c13",
   "metadata": {},
   "source": [
    "#### Importing data\n",
    "**Importing original sources** and **Importing extracted equations**\n",
    "\n",
    "> correct_eqs_list.csv\n",
    "\n",
    "> extracted_eqs.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1fdbdcd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['model', 'correct_eqs'], dtype='object'),\n",
       " Index(['model', 'extracted_eqs'], dtype='object'))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_eqs_df = pd.read_csv('/Users/kovacs.f/Desktop/mira/notebooks/F/correct_eqs_list.tsv', sep='\\t')\n",
    "extracted_eqs_df = pd.read_csv('/Users/kovacs.f/Desktop/mira/notebooks/F/extracted_eqs_VERSION001.tsv', sep='\\t')  #VERSION INPUT HERE -> TSV FILE NAME ENDING\n",
    "\n",
    "#check header names\n",
    "correct_eqs_df.columns, extracted_eqs_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be914b9",
   "metadata": {},
   "source": [
    "The aim is to compare the extracted models to their original form and analyse the results in order to detect the components of the process to be imporved and create the best possible extraction method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82912fb0",
   "metadata": {},
   "source": [
    "#### Feature Engineering\n",
    "Feature engineering in this case captures MIRA's extracted equations into numerical features that capture potential error patterns and extraction challenges. The error types expanded as features:\n",
    "\n",
    "1. Time-dependence inconsistencies\n",
    "2. Special symbol usage\n",
    "3. Sub- and superscript usage\n",
    "4. Undefined or unused parameters\n",
    "5. Equation graph structure (density, loops, etc.)\n",
    "6. Graphical features of the input pdf or png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e5d7146a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper functions for the feature extraction\n",
    "\n",
    "def _count_unicode_blocks(text):\n",
    "    \"\"\"Count different Unicode block types in text\"\"\"\n",
    "    blocks = set()\n",
    "    for char in text:\n",
    "        if ord(char) > 127:\n",
    "            code = ord(char)\n",
    "            if 0x0370 <= code <= 0x03FF:\n",
    "                blocks.add('GREEK')\n",
    "            elif 0x2200 <= code <= 0x22FF:\n",
    "                blocks.add('MATHEMATICAL_OPERATORS')\n",
    "            elif 0x2070 <= code <= 0x209F:\n",
    "                blocks.add('SUPERSCRIPTS_SUBSCRIPTS')\n",
    "            elif 0x1D400 <= code <= 0x1D7FF:\n",
    "                blocks.add('MATHEMATICAL_ALPHANUMERIC')\n",
    "            elif 0x2190 <= code <= 0x21FF:\n",
    "                blocks.add('ARROWS')\n",
    "    return len(blocks)\n",
    "\n",
    "def _calculate_encoding_complexity(text):\n",
    "    \"\"\"Calculate complexity based on character variety\"\"\"\n",
    "    if not text:\n",
    "        return 0\n",
    "    unique_chars = len(set(text))\n",
    "    total_chars = len(text)\n",
    "    # Add weight for non-ASCII characters\n",
    "    non_ascii = sum(1 for c in text if ord(c) > 127)\n",
    "    complexity = (unique_chars / total_chars) * 5 + (non_ascii / total_chars) * 5\n",
    "    return min(10, complexity)\n",
    "\n",
    "def _calculate_max_nesting_depth(text, delimiter):\n",
    "    \"\"\"Calculate maximum nesting depth for subscripts/superscripts\"\"\"\n",
    "    max_depth = 0\n",
    "    current_depth = 0\n",
    "    in_bracket = False\n",
    "    \n",
    "    for i, char in enumerate(text):\n",
    "        if char == delimiter and i + 1 < len(text) and text[i + 1] == '{':\n",
    "            current_depth += 1\n",
    "            max_depth = max(max_depth, current_depth)\n",
    "            in_bracket = True\n",
    "        elif char == '}' and in_bracket:\n",
    "            current_depth = max(0, current_depth - 1)\n",
    "            if current_depth == 0:\n",
    "                in_bracket = False\n",
    "    return max_depth\n",
    "\n",
    "def _count_single_occurrence_vars(text):\n",
    "    \"\"\"Count variables that appear only once (potentially undefined)\"\"\"\n",
    "    import re\n",
    "    # Find all single letter variables\n",
    "    variables = re.findall(r'\\b[a-zA-Z]\\b', text)\n",
    "    # Count those appearing only once\n",
    "    var_counts = Counter(variables)\n",
    "    return sum(1 for count in var_counts.values() if count == 1)\n",
    "\n",
    "def _calculate_parameter_consistency(text):\n",
    "    \"\"\"Score how consistently parameters are used (0-1)\"\"\"\n",
    "    import re\n",
    "    # Find all variables\n",
    "    variables = re.findall(r'\\b[a-zA-Z]+\\b', text)\n",
    "    if not variables:\n",
    "        return 1.0\n",
    "    \n",
    "    # Check consistency (simplified)\n",
    "    var_counts = Counter(variables)\n",
    "    # If all variables appear at least twice, good consistency\n",
    "    single_use = sum(1 for count in var_counts.values() if count == 1)\n",
    "    total_vars = len(var_counts)\n",
    "    \n",
    "    return 1.0 - (single_use / max(total_vars, 1))\n",
    "\n",
    "def _count_implicit_parameters(text):\n",
    "    \"\"\"Count parameters that seem assumed but not defined\"\"\"\n",
    "    import re\n",
    "    # Look for common parameter patterns not in derivatives\n",
    "    params = re.findall(r'\\b[a-zA-Z]\\b(?![\\'\"])', text)\n",
    "    # Common parameters that might be implicit\n",
    "    common_params = ['a', 'b', 'c', 'k', 'r', 'alpha', 'beta', 'gamma']\n",
    "    implicit_count = 0\n",
    "    for param in set(params):\n",
    "        if param in common_params and params.count(param) == 1:\n",
    "            implicit_count += 1\n",
    "    return implicit_count\n",
    "\n",
    "def _classify_naming_convention(text):\n",
    "    \"\"\"Classify variable naming style\"\"\"\n",
    "    import re\n",
    "    variables = re.findall(r'\\b[a-zA-Z_]+[a-zA-Z0-9_]*\\b', text)\n",
    "    if not variables:\n",
    "        return \"none\"\n",
    "    \n",
    "    # Check patterns\n",
    "    has_underscore = any('_' in var for var in variables)\n",
    "    has_multi_letter = any(len(var) > 1 for var in variables)\n",
    "    has_subscript = '_' in text\n",
    "    \n",
    "    if has_subscript:\n",
    "        return \"subscripted\"\n",
    "    elif has_multi_letter:\n",
    "        return \"multi_letter\"\n",
    "    else:\n",
    "        return \"single_letter\"\n",
    "\n",
    "def _extract_variables(text):\n",
    "    \"\"\"Extract all variables from equation\"\"\"\n",
    "    import re\n",
    "    # Extract single letters and multi-letter variables\n",
    "    variables = set(re.findall(r'\\b[a-zA-Z]+\\b', text))\n",
    "    # Remove common functions\n",
    "    functions = {'sin', 'cos', 'tan', 'exp', 'log', 'ln', 'sqrt', 'max', 'min'}\n",
    "    return variables - functions\n",
    "\n",
    "def _calculate_derivative_consistency(text):\n",
    "    \"\"\"Check if derivative notation is consistent\"\"\"\n",
    "    dot_notation = bool(re.search(r'[ẋẏżẍÿz̈]|\\\\dot\\{|\\\\ddot\\{', text))\n",
    "    prime_notation = \"'\" in text or \"′\" in text\n",
    "    leibniz_notation = bool(re.search(r'd[a-zA-Z]/d[a-zA-Z]|\\\\frac\\{d', text))\n",
    "    \n",
    "    notations_used = sum([dot_notation, prime_notation, leibniz_notation])\n",
    "    \n",
    "    # Consistent if only one notation used or no derivatives\n",
    "    if notations_used <= 1:\n",
    "        return 1.0\n",
    "    else:\n",
    "        return 0.5  # Mixed notation\n",
    "\n",
    "def _check_time_var_consistency(text):\n",
    "    \"\"\"Check if time variable is used consistently\"\"\"\n",
    "    import re\n",
    "    # Look for common time variables\n",
    "    time_vars = re.findall(r'\\b[tτ]\\b', text)\n",
    "    if not time_vars:\n",
    "        return True\n",
    "    \n",
    "    # Check if only one type is used\n",
    "    unique_vars = set(time_vars)\n",
    "    return len(unique_vars) == 1\n",
    "\n",
    "def _check_derivative_progression(text):\n",
    "    \"\"\"Check if derivative orders make sense\"\"\"\n",
    "    import re\n",
    "    # Look for derivative patterns\n",
    "    first_order = bool(re.search(r\"[a-zA-Z]'(?!')|\\b[a-zA-Z]\\b'\", text))\n",
    "    second_order = bool(re.search(r\"[a-zA-Z]''|\\\\ddot\", text))\n",
    "    \n",
    "    # If we have second order, we should have first order\n",
    "    if second_order and not first_order:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def _count_time_dependence_issues(text):\n",
    "    \"\"\"Count inconsistencies in time dependence notation\"\"\"\n",
    "    import re\n",
    "    # Count y vs y(t) style inconsistencies\n",
    "    bare_vars = len(re.findall(r'\\b[a-zA-Z]\\b(?!\\()', text))\n",
    "    function_vars = len(re.findall(r'\\b[a-zA-Z]\\([a-zA-Z]\\)', text))\n",
    "    \n",
    "    # If we have both styles, that's an issue\n",
    "    if bare_vars > 0 and function_vars > 0:\n",
    "        return min(bare_vars, function_vars)\n",
    "    return 0\n",
    "\n",
    "def _count_derivative_mismatches(text):\n",
    "    \"\"\"Count derivatives with undefined variables\"\"\"\n",
    "    import re\n",
    "    # Find derivatives like dy/dx\n",
    "    derivatives = re.findall(r'd([a-zA-Z])/d([a-zA-Z])', text)\n",
    "    mismatches = 0\n",
    "    \n",
    "    all_vars = set(re.findall(r'\\b[a-zA-Z]\\b', text))\n",
    "    \n",
    "    for dep_var, indep_var in derivatives:\n",
    "        if indep_var not in all_vars:\n",
    "            mismatches += 1\n",
    "    \n",
    "    return mismatches\n",
    "\n",
    "def _build_dependency_graph(text):\n",
    "    \"\"\"Build variable dependency graph\"\"\"\n",
    "    import re\n",
    "    # Simple version - just count variables and relationships\n",
    "    variables = set(re.findall(r'\\b[a-zA-Z]\\b', text))\n",
    "    \n",
    "    # Look for equations (separated by =)\n",
    "    equations = text.split('=')\n",
    "    edges = []\n",
    "    \n",
    "    for i in range(len(equations) - 1):\n",
    "        left_vars = set(re.findall(r'\\b[a-zA-Z]\\b', equations[i]))\n",
    "        right_vars = set(re.findall(r'\\b[a-zA-Z]\\b', equations[i + 1]))\n",
    "        for lv in left_vars:\n",
    "            for rv in right_vars:\n",
    "                if lv != rv:\n",
    "                    edges.append((lv, rv))\n",
    "    \n",
    "    return {'nodes': list(variables), 'edges': edges}\n",
    "\n",
    "def _calculate_graph_connectivity(text):\n",
    "    \"\"\"Calculate connectivity of variable graph\"\"\"\n",
    "    graph = _build_dependency_graph(text)\n",
    "    if not graph['nodes']:\n",
    "        return 0\n",
    "    \n",
    "    # Simple connectivity measure\n",
    "    num_edges = len(graph['edges'])\n",
    "    num_nodes = len(graph['nodes'])\n",
    "    \n",
    "    if num_nodes <= 1:\n",
    "        return 0\n",
    "    \n",
    "    # Normalized connectivity\n",
    "    max_edges = num_nodes * (num_nodes - 1)\n",
    "    return num_edges / max_edges if max_edges > 0 else 0\n",
    "\n",
    "def _check_cyclic_dependencies(text):\n",
    "    \"\"\"Check for circular dependencies\"\"\"\n",
    "    graph = _build_dependency_graph(text)\n",
    "    edges = graph['edges']\n",
    "    \n",
    "    # Simple cycle detection\n",
    "    for a, b in edges:\n",
    "        if (b, a) in edges:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def _calculate_coupling_strength(text):\n",
    "    \"\"\"Calculate how strongly equations are coupled\"\"\"\n",
    "    # Split by newlines or equation separators\n",
    "    equations = re.split(r'[,\\n\\\\\\\\]', text)\n",
    "    if len(equations) <= 1:\n",
    "        return 0\n",
    "    \n",
    "    # Find shared variables\n",
    "    all_vars = []\n",
    "    for eq in equations:\n",
    "        vars_in_eq = set(re.findall(r'\\b[a-zA-Z]\\b', eq))\n",
    "        all_vars.append(vars_in_eq)\n",
    "    \n",
    "    # Calculate overlap\n",
    "    if not all_vars:\n",
    "        return 0\n",
    "    \n",
    "    shared = set.intersection(*all_vars) if all_vars else set()\n",
    "    total = set.union(*all_vars) if all_vars else set()\n",
    "    \n",
    "    return len(shared) / len(total) if total else 0\n",
    "\n",
    "def _estimate_jacobian_sparsity(text):\n",
    "    \"\"\"Estimate sparsity of Jacobian matrix\"\"\"\n",
    "    graph = _build_dependency_graph(text)\n",
    "    num_vars = len(graph['nodes'])\n",
    "    \n",
    "    if num_vars == 0:\n",
    "        return 0\n",
    "    \n",
    "    # Estimate non-zero entries\n",
    "    num_edges = len(graph['edges'])\n",
    "    total_possible = num_vars * num_vars\n",
    "    \n",
    "    return 1 - (num_edges / total_possible) if total_possible > 0 else 1\n",
    "\n",
    "def _calculate_equation_similarity(text):\n",
    "    \"\"\"Calculate similarity between equations in system\"\"\"\n",
    "    equations = re.split(r'[,\\n\\\\\\\\]', text)\n",
    "    if len(equations) <= 1:\n",
    "        return 1.0\n",
    "    \n",
    "    # Simple character-based similarity\n",
    "    similarities = []\n",
    "    for i in range(len(equations)):\n",
    "        for j in range(i + 1, len(equations)):\n",
    "            eq1_chars = set(equations[i])\n",
    "            eq2_chars = set(equations[j])\n",
    "            if eq1_chars or eq2_chars:\n",
    "                similarity = len(eq1_chars & eq2_chars) / len(eq1_chars | eq2_chars)\n",
    "                similarities.append(similarity)\n",
    "    \n",
    "    return sum(similarities) / len(similarities) if similarities else 1.0\n",
    "\n",
    "def _count_terms(text):\n",
    "    \"\"\"Count mathematical terms in equation\"\"\"\n",
    "    # Split by operators\n",
    "    terms = re.split(r'[+\\-=]', text)\n",
    "    # Filter out empty strings\n",
    "    return len([t for t in terms if t.strip()])\n",
    "\n",
    "def _estimate_font_size(ocr_data):\n",
    "    \"\"\"Estimate font size from OCR data\"\"\"\n",
    "    if not ocr_data:\n",
    "        return 12\n",
    "    \n",
    "    bbox_height = ocr_data.get('bbox_height', 20)\n",
    "    # Rough estimation\n",
    "    return bbox_height * 0.75\n",
    "\n",
    "def _find_keyword_distance(equation_text, context_data):\n",
    "    \"\"\"Find distance to definition keywords\"\"\"\n",
    "    if not context_data:\n",
    "        return float('inf')\n",
    "    \n",
    "    text_before = context_data.get('text_before', '')\n",
    "    keywords = ['where', 'with', 'given', 'such that']\n",
    "    \n",
    "    min_distance = float('inf')\n",
    "    for keyword in keywords:\n",
    "        if keyword in text_before:\n",
    "            distance = len(text_before) - text_before.rfind(keyword)\n",
    "            min_distance = min(min_distance, distance)\n",
    "    \n",
    "    return min_distance\n",
    "\n",
    "def _classify_text_type(context_data):\n",
    "    \"\"\"Classify surrounding text type\"\"\"\n",
    "    if not context_data:\n",
    "        return \"unknown\"\n",
    "    \n",
    "    full_text = context_data.get('full_text', '').lower()\n",
    "    \n",
    "    if 'proof' in full_text:\n",
    "        return \"proof\"\n",
    "    elif 'theorem' in full_text:\n",
    "        return \"theorem\"\n",
    "    elif 'definition' in full_text:\n",
    "        return \"definition\"\n",
    "    elif 'example' in full_text:\n",
    "        return \"example\"\n",
    "    else:\n",
    "        return \"prose\"\n",
    "\n",
    "def _count_confusable_symbols(text):\n",
    "    \"\"\"Count easily confused symbols\"\"\"\n",
    "    confusables = [\n",
    "        ('0', 'O', 'o'),\n",
    "        ('1', 'l', 'I', '|'),\n",
    "        ('5', 'S', 's'),\n",
    "        ('2', 'Z', 'z')\n",
    "    ]\n",
    "    \n",
    "    count = 0\n",
    "    for group in confusables:\n",
    "        chars_in_text = sum(1 for char in text if char in group)\n",
    "        if chars_in_text > 1:  # Multiple from same group\n",
    "            count += chars_in_text\n",
    "    \n",
    "    return count\n",
    "\n",
    "def _count_similar_variables(text):\n",
    "    \"\"\"Count similar variable names\"\"\"\n",
    "    import re\n",
    "    variables = set(re.findall(r'\\b[a-zA-Z]\\b', text))\n",
    "    \n",
    "    similar_pairs = [\n",
    "        ('x', 'χ'), ('v', 'ν'), ('p', 'ρ'),\n",
    "        ('a', 'α'), ('b', 'β'), ('g', 'γ')\n",
    "    ]\n",
    "    \n",
    "    count = 0\n",
    "    for v1, v2 in similar_pairs:\n",
    "        if v1 in text and v2 in text:\n",
    "            count += 1\n",
    "    \n",
    "    return count\n",
    "\n",
    "def _determine_ode_order(text):\n",
    "    \"\"\"Determine ODE order\"\"\"\n",
    "    import re\n",
    "    # Look for derivative patterns\n",
    "    second_order = bool(re.search(r\"d²|\\\\frac\\{d\\^2|''|\\\\ddot\", text))\n",
    "    third_order = bool(re.search(r\"d³|\\\\frac\\{d\\^3|'''\", text))\n",
    "    \n",
    "    if third_order:\n",
    "        return 3\n",
    "    elif second_order:\n",
    "        return 2\n",
    "    elif 'd' in text or \"'\" in text or '\\\\dot' in text:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def _check_linearity(text):\n",
    "    \"\"\"Check if ODE is linear\"\"\"\n",
    "    # Simplified check - look for products of variables\n",
    "    import re\n",
    "    variables = re.findall(r'\\b[a-zA-Z]\\b', text)\n",
    "    \n",
    "    # Check for products like xy, x^2\n",
    "    for i in range(len(text) - 1):\n",
    "        if text[i].isalpha() and text[i+1].isalpha():\n",
    "            return False\n",
    "        if text[i].isalpha() and text[i+1] == '^':\n",
    "            return False\n",
    "    \n",
    "    return True\n",
    "\n",
    "def _check_autonomous(text):\n",
    "    \"\"\"Check if ODE is autonomous\"\"\"\n",
    "    # Check if time variable appears explicitly\n",
    "    time_vars = ['t', 'τ', 'time']\n",
    "    \n",
    "    for var in time_vars:\n",
    "        # Check if it appears not as derivative variable\n",
    "        if re.search(rf'\\b{var}\\b(?![)])', text):\n",
    "            return False\n",
    "    \n",
    "    return True\n",
    "\n",
    "def _check_forcing_term(text):\n",
    "    \"\"\"Check for forcing/source terms\"\"\"\n",
    "    # Look for common forcing term patterns\n",
    "    forcing_patterns = [\n",
    "        r'sin\\(.*t',\n",
    "        r'cos\\(.*t',\n",
    "        r'e\\^.*t',\n",
    "        r'f\\(t\\)',\n",
    "        r'g\\(t\\)'\n",
    "    ]\n",
    "    \n",
    "    for pattern in forcing_patterns:\n",
    "        if re.search(pattern, text):\n",
    "            return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "def _check_standard_forms(text):\n",
    "    \"\"\"Check if matches standard ODE forms\"\"\"\n",
    "    # Check for common forms\n",
    "    separable = bool(re.search(r'\\\\frac\\{dy\\}\\{dx\\}\\s*=.*f\\(x\\).*g\\(y\\)', text))\n",
    "    exact = bool(re.search(r'M.*dx.*\\+.*N.*dy.*=.*0', text))\n",
    "    \n",
    "    return separable or exact\n",
    "\n",
    "def _calculate_parenthesis_depth(text):\n",
    "    \"\"\"Calculate maximum nesting depth of parentheses\"\"\"\n",
    "    max_depth = 0\n",
    "    current_depth = 0\n",
    "    \n",
    "    for char in text:\n",
    "        if char == '(':\n",
    "            current_depth += 1\n",
    "            max_depth = max(max_depth, current_depth)\n",
    "        elif char == ')':\n",
    "            current_depth = max(0, current_depth - 1)\n",
    "    \n",
    "    return max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "03f2fb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(equation_text, ocr_data=None, context_data=None):\n",
    "    features = {}\n",
    "       \n",
    "    # ========== SPECIAL SYMBOLS & GREEK LETTERS ==========\n",
    "       \n",
    "    # Binary: contains any Greek letters (α, β, γ, etc.)\n",
    "    features['contains_greek_letters'] = bool(re.search(r'[α-ωΑ-Ω]|\\\\(alpha|beta|gamma|delta|epsilon|theta|lambda|mu|nu|xi|pi|rho|sigma|tau|phi|chi|psi|omega)', equation_text))\n",
    "       \n",
    "    # Count: total number of Greek letters in equation\n",
    "    features['num_greek_letters'] = len(re.findall(r'[α-ωΑ-Ω]|\\\\(alpha|beta|gamma|delta|epsilon|theta|lambda|mu|nu|xi|pi|rho|sigma|tau|phi|chi|psi|omega)', equation_text))\n",
    "       \n",
    "    # Ratio: unicode (not ASCII) characters / total characters (higher = more special symbols)\n",
    "    features['unicode_ratio'] = len([c for c in equation_text if ord(c) > 127]) / max(len(equation_text), 1)\n",
    "       \n",
    "    # Count: different unicode block types (Greek, Mathematical, etc.)\n",
    "    features['unicode_block_diversity'] = _count_unicode_blocks(equation_text)\n",
    "       \n",
    "    # Count: rare mathematical symbols (∀, ∃, ∈, ∅, etc.)\n",
    "    features['rare_symbol_count'] = len(re.findall(r'[∀∃∈∅⊂⊃⊆⊇∪∩≡≈≠≤≥∞∇∂]', equation_text))\n",
    "       \n",
    "    # Score: complexity based on character encoding variety\n",
    "    features['encoding_complexity_score'] = _calculate_encoding_complexity(equation_text)\n",
    "       \n",
    "    # ========== SUBSCRIPTS & SUPERSCRIPTS ==========\n",
    "       \n",
    "    # Binary: has subscripts (x_i or x_{ij})\n",
    "    features['has_subscripts'] = '_' in equation_text or '_{' in equation_text\n",
    "       \n",
    "    # Count: total number of subscripts\n",
    "    features['num_subscripts'] = equation_text.count('_')\n",
    "       \n",
    "    # Binary: has nested subscripts (x_{i_j} or deeper)\n",
    "    features['has_nested_subscripts'] = bool(re.search(r'_\\{[^}]*_', equation_text))\n",
    "       \n",
    "    # Count: maximum subscript nesting depth (x_{i_{j_{k}}} = 3)\n",
    "    features['max_subscript_depth'] = _calculate_max_nesting_depth(equation_text, '_')\n",
    "\n",
    "    # Binary: has superscripts (x^i or x^{ij})\n",
    "    features['has_superscripts'] = '^' in equation_text or '^{' in equation_text\n",
    "\n",
    "    # Count: total number of superscripts\n",
    "    features['num_superscripts'] = equation_text.count('^')  # Also fixed the typo: num_supescripts → num_superscripts\n",
    "       \n",
    "    \n",
    "    # Count: mixed subscript/superscript (x_i^j)\n",
    "    features['mixed_sub_super_count'] = len(re.findall(r'_[^_\\s]+\\^|_\\{[^}]+\\}\\^', equation_text))\n",
    "       \n",
    "    # Binary: has numeric subscripts (x_1, x_2)\n",
    "    features['has_numeric_subscripts'] = bool(re.search(r'_\\d|_\\{\\d', equation_text))\n",
    "       \n",
    "    # Binary: has alphabetic subscripts (x_i, x_j)\n",
    "    features['has_alphabetic_subscripts'] = bool(re.search(r'_[a-zA-Z]|_\\{[a-zA-Z]', equation_text))\n",
    "\n",
    "    # ========== PARAMETERS & VARIABLES ==========\n",
    "       \n",
    "    # Count: variables that appear only once (potential undefined)\n",
    "    features['undefined_variable_candidates'] = _count_single_occurrence_vars(equation_text)\n",
    "       \n",
    "    # Score: how consistently parameters are used (0-1, 1=perfect)\n",
    "    features['parameter_consistency_score'] = _calculate_parameter_consistency(equation_text)\n",
    "       \n",
    "    # Count: parameters that seem assumed but not defined\n",
    "    features['implicit_parameter_count'] = _count_implicit_parameters(equation_text)\n",
    "       \n",
    "    # Category: naming style (single_letter/subscripted/multi_letter)\n",
    "    features['parameter_naming_convention'] = _classify_naming_convention(equation_text)\n",
    "       \n",
    "    # Count: total unique variables\n",
    "    features['num_unique_variables'] = len(_extract_variables(equation_text))\n",
    "       \n",
    "    # ========== TIME DEPENDENCE & DERIVATIVES ==========\n",
    "       \n",
    "    # Binary: uses dot notation for derivatives (ẋ, ẍ)\n",
    "    features['uses_dot_notation'] = bool(re.search(r'[ẋẏżẍÿz̈]|\\\\dot\\{|\\\\ddot\\{', equation_text))\n",
    "       \n",
    "    # Binary: uses prime notation (y', y'')\n",
    "    features['uses_prime_notation'] = \"'\" in equation_text or \"′\" in equation_text or \"″\" in equation_text\n",
    "       \n",
    "    # Binary: uses Leibniz notation (dy/dx, d²y/dx²)\n",
    "    features['uses_leibniz_notation'] = bool(re.search(r'd[a-zA-Z]/d[a-zA-Z]|\\\\frac\\{d', equation_text))\n",
    "       \n",
    "    # Binary: mixed derivative notations in same equation\n",
    "    features['mixed_derivative_notation'] = sum([features['uses_dot_notation'], features['uses_prime_notation'], features['uses_leibniz_notation']]) > 1\n",
    "       \n",
    "    # Score: how consistently derivative notation is used\n",
    "    features['derivative_notation_consistency'] = _calculate_derivative_consistency(equation_text)\n",
    "       \n",
    "    # Binary: consistent time variable (always 't' or always 'τ')\n",
    "    features['time_variable_consistency'] = _check_time_var_consistency(equation_text)\n",
    "       \n",
    "    # Binary: derivative order makes sense (has y' if has y'')\n",
    "    features['derivative_order_progression'] = _check_derivative_progression(equation_text)\n",
    "       \n",
    "    # Count: y vs y(t) inconsistencies\n",
    "    features['implicit_time_dependence_issues'] = _count_time_dependence_issues(equation_text)\n",
    "       \n",
    "    # Count: derivatives with undefined variables (dy/dx but no x)\n",
    "    features['derivative_variable_mismatch'] = _count_derivative_mismatches(equation_text)\n",
    "       \n",
    "    # ========== GRAPH STRUCTURE & COMPLEXITY ==========\n",
    "       \n",
    "    # Count: number of variables in ODE system\n",
    "    features['dependency_graph_nodes'] = len(_build_dependency_graph(equation_text)['nodes'])\n",
    "       \n",
    "    # Count: variable relationships (x appears with y)\n",
    "    features['dependency_graph_edges'] = len(_build_dependency_graph(equation_text)['edges'])\n",
    "       \n",
    "    # Count: strongly connected components in variable graph\n",
    "    features['graph_connectivity'] = _calculate_graph_connectivity(equation_text)\n",
    "       \n",
    "    # Binary: has circular dependencies (x depends on y, y on x)\n",
    "    features['has_cyclic_dependencies'] = _check_cyclic_dependencies(equation_text)\n",
    "       \n",
    "    # Score: how many equations share variables (0-1)\n",
    "    features['coupling_strength'] = _calculate_coupling_strength(equation_text)\n",
    "       \n",
    "    # Ratio: non-zero entries in Jacobian matrix\n",
    "    features['jacobian_sparsity'] = _estimate_jacobian_sparsity(equation_text)\n",
    "       \n",
    "    # Score: average similarity between equations in system\n",
    "    features['equation_similarity_score'] = _calculate_equation_similarity(equation_text)\n",
    "       \n",
    "    # Count: total terms in equation\n",
    "    features['total_term_count'] = _count_terms(equation_text)\n",
    "       \n",
    "    # ========== VISUAL FEATURES (requires OCR data) ==========\n",
    "       \n",
    "    if ocr_data:\n",
    "        # Area: size of equation bounding box in pixels\n",
    "        features['bounding_box_area'] = ocr_data.get('bbox_area', 0)\n",
    "           \n",
    "        # Ratio: width/height of equation region\n",
    "        features['bounding_box_aspect_ratio'] = ocr_data.get('bbox_width', 1) / max(ocr_data.get('bbox_height', 1), 1)\n",
    "           \n",
    "        # Density: characters per pixel area\n",
    "        features['character_density'] = len(equation_text) / max(features['bounding_box_area'], 1)\n",
    "           \n",
    "        # Ratio: whitespace pixels / total pixels\n",
    "        features['whitespace_ratio'] = ocr_data.get('whitespace_ratio', 0)\n",
    "           \n",
    "        # Score: average OCR confidence (0-1)\n",
    "        features['ocr_confidence_mean'] = ocr_data.get('confidence_scores', [0.5])[0] if ocr_data.get('confidence_scores') else 0.5\n",
    "           \n",
    "        # Score: standard deviation of OCR confidence\n",
    "        features['ocr_confidence_std'] = np.std(ocr_data.get('confidence_scores', [0.5]))\n",
    "           \n",
    "        # Count: characters with confidence < 0.7\n",
    "        features['low_confidence_char_count'] = sum(1 for c in ocr_data.get('char_confidences', []) if c < 0.7)\n",
    "           \n",
    "        # Pixels: estimated font size from bbox\n",
    "        features['font_size_estimate'] = _estimate_font_size(ocr_data)\n",
    "           \n",
    "        # Score: how well multi-line equations align (0-1)\n",
    "        features['alignment_score'] = ocr_data.get('alignment_score', 0)\n",
    "           \n",
    "        # Count: overlapping character regions\n",
    "        features['overlapping_regions'] = ocr_data.get('overlap_count', 0)\n",
    "       \n",
    "    # ========== CONTEXT FEATURES ==========\n",
    "    if context_data:\n",
    "           # Binary: has \"where x is...\" before/after equation\n",
    "           features['has_preceding_definition'] = bool(re.search(r'where|with|given|such that', context_data.get('text_before', '')))\n",
    "           \n",
    "           # Distance: characters to nearest definition keyword\n",
    "           features['definition_keyword_distance'] = _find_keyword_distance(equation_text, context_data)\n",
    "           \n",
    "           # Binary: equation has label like (1), (2.3), Eq. 1\n",
    "           features['equation_label_present'] = bool(re.search(r'\\(\\d+\\.?\\d*\\)|Eq\\.?\\s*\\d+', context_data.get('full_text', '')))\n",
    "           \n",
    "           # Binary: in LaTeX equation environment\n",
    "           features['in_equation_environment'] = '\\\\begin{equation}' in context_data.get('full_text', '')\n",
    "           \n",
    "           # Category: prose/list/proof/theorem/definition\n",
    "           features['surrounding_text_type'] = _classify_text_type(context_data)\n",
    "           \n",
    "           # Binary: references previous equations\n",
    "           features['references_previous_equation'] = bool(re.search(r'equation\\s*\\(\\d+\\)|from\\s*\\(\\d+\\)|see\\s*\\(\\d+\\)', context_data.get('text_after', '')))\n",
    "           \n",
    "           # Binary: has boundary/initial condition keywords\n",
    "           features['has_boundary_condition_text'] = bool(re.search(r'subject to|with IC|initial condition|boundary condition|BC:|IC:', context_data.get('full_text', '')))\n",
    "           \n",
    "           # Binary: domain specified (for x ∈ [0,1])\n",
    "           features['domain_specification_present'] = bool(re.search(r'for\\s+[a-zA-Z]\\s*[∈∊]\\s*[\\[\\(]|[a-zA-Z]\\s*in\\s*[\\[\\(]', context_data.get('full_text', '')))\n",
    "       \n",
    "       # ========== AMBIGUITY FEATURES ==========\n",
    "       \n",
    "    # Count: ambiguous notations (log vs ln, etc.)\n",
    "    features['ambiguous_notation_count'] = len(re.findall(r'\\b(log|arg|det|dim|ker|span)\\b', equation_text))\n",
    "       \n",
    "    # Count: implicit multiplications (xy vs x*y)\n",
    "    features['implicit_multiplication_count'] = len(re.findall(r'[a-zA-Z]\\d|[a-zA-Z][a-zA-Z]|\\d[a-zA-Z]', equation_text))\n",
    "       \n",
    "    # Count: easily confused symbols (0/O, 1/l/I)\n",
    "    features['confusable_symbol_count'] = _count_confusable_symbols(equation_text)\n",
    "       \n",
    "    # Count: similar variable names (x/χ, v/ν, p/ρ)\n",
    "    features['similar_variable_count'] = _count_similar_variables(equation_text)\n",
    "       \n",
    "    # ========== ODE-SPECIFIC FEATURES ==========\n",
    "       \n",
    "    # Order: highest derivative order (1, 2, 3, etc.)\n",
    "    features['ode_order'] = _determine_ode_order(equation_text)\n",
    "       \n",
    "    # Binary: is linear ODE\n",
    "    features['is_linear_ode'] = _check_linearity(equation_text)\n",
    "       \n",
    "    # Binary: is autonomous (no explicit time variable)\n",
    "    features['is_autonomous'] = _check_autonomous(equation_text)\n",
    "       \n",
    "    # Binary: has forcing/source term\n",
    "    features['has_forcing_term'] = _check_forcing_term(equation_text)\n",
    "       \n",
    "    # Count: number of coupled equations\n",
    "    features['num_coupled_equations'] = equation_text.count('=') if '=' in equation_text else 0\n",
    "       \n",
    "    # Binary: matches standard forms (separable, exact, etc.)\n",
    "    features['is_standard_form'] = _check_standard_forms(equation_text)\n",
    "       \n",
    "    # Length: total character count\n",
    "    features['equation_length'] = len(equation_text)\n",
    "       \n",
    "    # Binary: is multi-line equation\n",
    "    features['is_multiline'] = '\\n' in equation_text or '\\\\\\\\' in equation_text\n",
    "       \n",
    "    # Count: number of lines\n",
    "    features['num_lines'] = equation_text.count('\\n') + equation_text.count('\\\\\\\\') + 1\n",
    "\n",
    "     # ========== MATHEMATICAL OPERATIONS ==========\n",
    "\n",
    "    # Binary: has derivatives (any notation)\n",
    "    features['has_derivatives'] = any([\n",
    "        features['uses_dot_notation'],\n",
    "        features['uses_prime_notation'], \n",
    "        features['uses_leibniz_notation']\n",
    "        ])\n",
    "    \n",
    "    # Binary: has integrals (∫ or \\int or \\iint or \\oint etc.)\n",
    "    features['has_integrals'] = bool(re.search(r'∫|∬|∭|∮|\\\\int|\\\\iint|\\\\iiint|\\\\oint|\\\\smallint', equation_text))\n",
    "\n",
    "    # Binary: has summation\n",
    "    features['has_summation'] = bool(re.search(r'∑|\\\\sum', equation_text))\n",
    "\n",
    "    # Binary: has product notation\n",
    "    features['has_product'] = bool(re.search(r'∏|\\\\prod', equation_text))\n",
    "\n",
    "\n",
    "    # Binary: has special functions\n",
    "    features['has_special_functions'] = bool(re.search(\n",
    "        r'(sin|cos|tan|sinh|cosh|tanh|exp|log|ln|sqrt|erf|gamma|bessel|arcsin|arccos|arctan)',\n",
    "        equation_text, re.IGNORECASE\n",
    "        ))\n",
    "\n",
    "    # Binary: has fractions\n",
    "    features['has_fractions'] = bool(re.search(r'/|\\\\frac|\\\\dfrac|\\\\tfrac', equation_text))\n",
    "\n",
    "    # Binary: has matrices\n",
    "    features['has_matrices'] = bool(re.search(\n",
    "      r'\\\\begin\\{[pbvBV]?matrix\\}|\\\\matrix|\\\\det|\\\\text\\{det\\}|\\\\begin\\{array\\}',\n",
    "     equation_text\n",
    "    ))\n",
    "\n",
    "    # Count: mathematical operations\n",
    "    features['num_additions'] = equation_text.count('+')\n",
    "    features['num_subtractions'] = equation_text.count('-') - equation_text.count('e-')  # Exclude scientific notation\n",
    "    features['num_multiplications'] = equation_text.count('*') + equation_text.count('·') + equation_text.count('\\\\cdot') + equation_text.count('\\\\times')\n",
    "    features['num_divisions'] = equation_text.count('/') + equation_text.count('÷') + equation_text.count('\\\\div')\n",
    "\n",
    "    # ========== STRUCTURAL FEATURES ==========\n",
    "\n",
    "    # Count: parentheses pairs\n",
    "    features['num_parentheses_pairs'] = min(equation_text.count('('), equation_text.count(')'))\n",
    "\n",
    "    # Count: maximum nesting depth of parentheses\n",
    "    features['max_nesting_depth'] = _calculate_parenthesis_depth(equation_text)\n",
    "       \n",
    "       \n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c847d12",
   "metadata": {},
   "source": [
    "#### 3-step comparison of ODE systems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b7a234",
   "metadata": {},
   "source": [
    "##### STEP 1: Extract features and calculate scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8ed49412",
   "metadata": {},
   "outputs": [],
   "source": [
    "def step1_extract_and_score_features(correct_df):\n",
    "    all_features = []\n",
    "    skipped_count = 0\n",
    "    \n",
    "    for _, row in correct_df.iterrows():\n",
    "        equation = row['correct_eqs']\n",
    "        model = row['model']\n",
    "\n",
    "        if pd.isna(equation) or equation is None:\n",
    "            print(f\"Skipping {model} - no equation data\")\n",
    "            skipped_count += 1\n",
    "            continue\n",
    "            \n",
    "        equation = str(equation)\n",
    "        \n",
    "        if not equation.strip() or equation == 'nan':\n",
    "            print(f\"Skipping {model} - empty equation\")\n",
    "            skipped_count += 1\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            # extracting all features\n",
    "            features = extract_features(equation)\n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting features for {model}: {e}\")\n",
    "            skipped_count += 1\n",
    "            continue\n",
    "        \n",
    "        features['model'] = model\n",
    "        features['original_equation'] = equation\n",
    "        \n",
    "        # calculating different complexity scores\n",
    "\n",
    "        # 1. Symbol Complexity Score (0-10)\n",
    "        symbol_score = (\n",
    "            features['contains_greek_letters'] * 2 +\n",
    "            features['num_greek_letters'] * 0.5 +\n",
    "            features['unicode_ratio'] * 10 +\n",
    "            features['rare_symbol_count'] * 1 +\n",
    "            features['encoding_complexity_score']\n",
    "        )\n",
    "        features['symbol_complexity_score'] = min(10, symbol_score)\n",
    "\n",
    "        # 2. Structural Complexity Score (0-10)\n",
    "        structural_score = (\n",
    "            features['has_subscripts'] * 1 +\n",
    "            features['num_subscripts'] * 0.3 +\n",
    "            features['has_superscripts'] * 1 +\n",
    "            features['num_superscripts'] * 0.3 +\n",
    "            features['max_subscript_depth'] * 2 +\n",
    "            features['has_nested_subscripts'] * 3 +\n",
    "            features['mixed_sub_super_count'] * 0.5\n",
    "        )\n",
    "        features['structural_complexity_score'] = min(10, structural_score)\n",
    "\n",
    "        # 3. Mathematical Complexity Score (0-10)\n",
    "        math_score = (\n",
    "            features['ode_order'] * 1.5 +\n",
    "            features['num_coupled_equations'] * 2 +\n",
    "            features['has_integrals'] * 1 +\n",
    "            features['has_derivatives'] * 0.5 +\n",
    "            features['has_summation'] * 1 +\n",
    "            features['has_special_functions'] * 1.5 +\n",
    "            (not features['is_linear_ode']) * 2 +\n",
    "            features['total_term_count'] * 0.1\n",
    "        )\n",
    "        features['mathematical_complexity_score'] = min(10, math_score)\n",
    "\n",
    "        # 4. Visual Complexity Score (0-10)\n",
    "        visual_score = (\n",
    "            features['is_multiline'] * 3 +\n",
    "            features['num_lines'] * 0.5 +\n",
    "            features['equation_length'] / 50 +  # Normalized by typical length\n",
    "            features['num_parentheses_pairs'] * 0.3 +\n",
    "            features['max_nesting_depth'] * 1 +\n",
    "            features['has_matrices'] * 2\n",
    "        )\n",
    "        features['visual_complexity_score'] = min(10, visual_score)\n",
    "\n",
    "        # 5. Overall Complexity Score (0-10)\n",
    "        features['overall_complexity_score'] = (\n",
    "            features['symbol_complexity_score'] * 0.3 +\n",
    "            features['structural_complexity_score'] * 0.25 +\n",
    "            features['mathematical_complexity_score'] * 0.25 +\n",
    "            features['visual_complexity_score'] * 0.2\n",
    "        )\n",
    "\n",
    "        # Risk Assessment Scores\n",
    "\n",
    "        # OCR Risk Score (0-10) - likelihood of OCR errors\n",
    "        features['ocr_risk_score'] = (\n",
    "            features['unicode_ratio'] * 15 +\n",
    "            features['contains_greek_letters'] * 2 +\n",
    "            features['num_greek_letters'] * 0.3 +\n",
    "            features['confusable_symbol_count'] * 1 +\n",
    "            features['similar_variable_count'] * 0.5 +\n",
    "            features['implicit_multiplication_count'] * 0.2\n",
    "        )\n",
    "        features['ocr_risk_score'] = min(10, features['ocr_risk_score'])\n",
    "\n",
    "        # Extraction Difficulty Score (0-10)\n",
    "        features['extraction_difficulty_score'] = (\n",
    "            features['overall_complexity_score'] * 0.4 +\n",
    "            features['ocr_risk_score'] * 0.6\n",
    "        )\n",
    "\n",
    "        # Feature Counts Summary\n",
    "        features['total_special_symbols'] = (\n",
    "            features['num_greek_letters'] +\n",
    "            features['rare_symbol_count'] +\n",
    "            features['num_subscripts'] +\n",
    "            features['num_superscripts']\n",
    "        )\n",
    "\n",
    "        features['total_mathematical_operations'] = (\n",
    "            features['num_additions'] +\n",
    "            features['num_subtractions'] +\n",
    "            features['num_multiplications'] +\n",
    "            features['num_divisions'] +\n",
    "            features['has_integrals'] +\n",
    "            features['has_summation'] +\n",
    "            features['has_product']\n",
    "        )\n",
    "\n",
    "        features['total_complexity_indicators'] = sum([\n",
    "            features['contains_greek_letters'],\n",
    "            features['has_subscripts'],\n",
    "            features['has_superscripts'],\n",
    "            features['has_fractions'],\n",
    "            features['has_integrals'],\n",
    "            features['has_derivatives'],\n",
    "            features['has_matrices'],\n",
    "            features['has_special_functions'],\n",
    "            features['is_multiline'],\n",
    "            features['mixed_derivative_notation']\n",
    "        ])\n",
    "        \n",
    "        # Risk Categories\n",
    "        if features['extraction_difficulty_score'] < 3:\n",
    "            features['risk_category'] = 'low'\n",
    "        elif features['extraction_difficulty_score'] < 6:\n",
    "            features['risk_category'] = 'medium'\n",
    "        elif features['extraction_difficulty_score'] < 8:\n",
    "            features['risk_category'] = 'high'\n",
    "        else:\n",
    "            features['risk_category'] = 'very_high'\n",
    "        \n",
    "        # Specific risk flags\n",
    "        features['has_high_risk_features'] = any([\n",
    "            features['unicode_ratio'] > 0.3,\n",
    "            features['max_subscript_depth'] > 2,\n",
    "            features['num_greek_letters'] > 5,\n",
    "            features['mixed_derivative_notation'],\n",
    "            features['has_matrices']\n",
    "        ])\n",
    "        \n",
    "        all_features.append(features)\n",
    "    \n",
    "    # creating features_df\n",
    "    features_df = pd.DataFrame(all_features)\n",
    "    \n",
    "    # summary statistics\n",
    "    print(\"\\n Feature Extraction Summary\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"Total equations analyzed: {len(features_df)}\")\n",
    "    print(f\"\\nComplexity Score Distribution:\")\n",
    "    print(f\"  Low (0-3): {len(features_df[features_df['overall_complexity_score'] < 3])}\")\n",
    "    print(f\"  Medium (3-6): {len(features_df[(features_df['overall_complexity_score'] >= 3) & (features_df['overall_complexity_score'] < 6)])}\")\n",
    "    print(f\"  High (6-8): {len(features_df[(features_df['overall_complexity_score'] >= 6) & (features_df['overall_complexity_score'] < 8)])}\")\n",
    "    print(f\"  Very High (8-10): {len(features_df[features_df['overall_complexity_score'] >= 8])}\")\n",
    "    \n",
    "    print(f\"\\nRisk Categories:\")\n",
    "    print(features_df['risk_category'].value_counts())\n",
    "    \n",
    "    print(f\"\\nTop 5 Most Complex Equations:\")\n",
    "    top_complex = features_df.nlargest(5, 'overall_complexity_score')[['model', 'overall_complexity_score', 'risk_category']]\n",
    "    print(top_complex)\n",
    "    \n",
    "    # feature statistics\n",
    "    print(f\"\\nFeature Statistics:\")\n",
    "    print(f\"  Equations with Greek letters: {features_df['contains_greek_letters'].sum()} ({features_df['contains_greek_letters'].mean()*100:.1f}%)\")\n",
    "    print(f\"  Equations with subscripts: {features_df['has_subscripts'].sum()} ({features_df['has_subscripts'].mean()*100:.1f}%)\")\n",
    "    print(f\"  Multi-line equations: {features_df['is_multiline'].sum()} ({features_df['is_multiline'].mean()*100:.1f}%)\")\n",
    "    print(f\"  Average ODE order: {features_df['ode_order'].mean():.2f}\")\n",
    "    print(f\"  Average complexity indicators per equation: {features_df['total_complexity_indicators'].mean():.2f}\")\n",
    "    \n",
    "    return features_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d61a5e9",
   "metadata": {},
   "source": [
    "> these need to be checked if they are useful:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3818eb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extras for step 1:\n",
    "\n",
    "# Helper function to create a feature summary report\n",
    "def create_feature_summary_report(features_df):\n",
    "   # Create a summary report of feature distributions and risk assessments\n",
    "   report = {\n",
    "       'total_equations': len(features_df),\n",
    "       'complexity_distribution': {\n",
    "           'low': len(features_df[features_df['overall_complexity_score'] < 3]),\n",
    "           'medium': len(features_df[(features_df['overall_complexity_score'] >= 3) & (features_df['overall_complexity_score'] < 6)]),\n",
    "           'high': len(features_df[(features_df['overall_complexity_score'] >= 6) & (features_df['overall_complexity_score'] < 8)]),\n",
    "           'very_high': len(features_df[features_df['overall_complexity_score'] >= 8])\n",
    "       },\n",
    "       'risk_distribution': features_df['risk_category'].value_counts().to_dict(),\n",
    "       'feature_prevalence': {\n",
    "           'greek_letters': features_df['contains_greek_letters'].mean(),\n",
    "           'subscripts': features_df['has_subscripts'].mean(),\n",
    "           'superscripts': features_df['has_superscripts'].mean(),\n",
    "           'fractions': features_df['has_fractions'].mean(),\n",
    "           'integrals': features_df['has_integrals'].mean(),\n",
    "           'derivatives': features_df['has_derivatives'].mean(),\n",
    "           'multiline': features_df['is_multiline'].mean()\n",
    "       },\n",
    "       'average_scores': {\n",
    "           'symbol_complexity': features_df['symbol_complexity_score'].mean(),\n",
    "           'structural_complexity': features_df['structural_complexity_score'].mean(),\n",
    "           'mathematical_complexity': features_df['mathematical_complexity_score'].mean(),\n",
    "           'visual_complexity': features_df['visual_complexity_score'].mean(),\n",
    "           'overall_complexity': features_df['overall_complexity_score'].mean(),\n",
    "           'ocr_risk': features_df['ocr_risk_score'].mean(),\n",
    "           'extraction_difficulty': features_df['extraction_difficulty_score'].mean()\n",
    "       },\n",
    "       'high_risk_equations': features_df[features_df['has_high_risk_features']]['model'].tolist()\n",
    "   }\n",
    "   \n",
    "   return report\n",
    "\n",
    "# Visualization function for feature analysis\n",
    "def visualize_feature_analysis(features_df):\n",
    "   # Create visualizations of feature distributions and complexity scores\n",
    "   import matplotlib.pyplot as plt\n",
    "   import seaborn as sns\n",
    "   \n",
    "   fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "   \n",
    "   # 1. Complexity score distribution\n",
    "   axes[0, 0].hist(features_df['overall_complexity_score'], bins=20, edgecolor='black')\n",
    "   axes[0, 0].set_title('Overall Complexity Score Distribution')\n",
    "   axes[0, 0].set_xlabel('Complexity Score (0-10)')\n",
    "   axes[0, 0].set_ylabel('Number of Equations')\n",
    "   \n",
    "   # 2. Risk category pie chart\n",
    "   risk_counts = features_df['risk_category'].value_counts()\n",
    "   axes[0, 1].pie(risk_counts.values, labels=risk_counts.index, autopct='%1.1f%%')\n",
    "   axes[0, 1].set_title('Risk Category Distribution')\n",
    "   \n",
    "   # 3. Feature prevalence bar chart\n",
    "   feature_cols = ['contains_greek_letters', 'has_subscripts', 'has_superscripts', \n",
    "                  'has_fractions', 'has_integrals', 'has_derivatives', 'is_multiline']\n",
    "   feature_prevalence = [features_df[col].mean() * 100 for col in feature_cols]\n",
    "   feature_names = ['Greek', 'Subscripts', 'Superscripts', 'Fractions', \n",
    "                   'Integrals', 'Derivatives', 'Multi-line']\n",
    "   \n",
    "   axes[1, 0].bar(feature_names, feature_prevalence)\n",
    "   axes[1, 0].set_title('Feature Prevalence (%)')\n",
    "   axes[1, 0].set_ylabel('Percentage of Equations')\n",
    "   axes[1, 0].set_xticklabels(feature_names, rotation=45)\n",
    "   \n",
    "   # 4. Complexity components scatter\n",
    "   axes[1, 1].scatter(features_df['symbol_complexity_score'], \n",
    "                     features_df['ocr_risk_score'], \n",
    "                     c=features_df['overall_complexity_score'], \n",
    "                     cmap='RdYlBu_r', alpha=0.6)\n",
    "   axes[1, 1].set_xlabel('Symbol Complexity Score')\n",
    "   axes[1, 1].set_ylabel('OCR Risk Score')\n",
    "   axes[1, 1].set_title('Symbol Complexity vs OCR Risk')\n",
    "   cbar = plt.colorbar(axes[1, 1].collections[0], ax=axes[1, 1])\n",
    "   cbar.set_label('Overall Complexity')\n",
    "   \n",
    "   plt.tight_layout()\n",
    "   plt.savefig('feature_analysis_summary.png', dpi=300)\n",
    "   plt.show()\n",
    "\n",
    "# Main execution for Step 1\n",
    "def run_step1_analysis(correct_df):\n",
    "   # Run complete Step 1 analysis\n",
    "   print(\"Starting Step 1: Feature Extraction and Scoring\")\n",
    "   print(\"-\" * 50)\n",
    "   \n",
    "   # Extract features and calculate scores\n",
    "   features_df = step1_extract_and_score_features(correct_df)\n",
    "   \n",
    "   # Create summary report\n",
    "   summary_report = create_feature_summary_report(features_df)\n",
    "   \n",
    "   # Save results\n",
    "   features_df.to_csv('equation_features_with_scores.csv', index=False)\n",
    "   \n",
    "   # Create visualizations\n",
    "   visualize_feature_analysis(features_df)\n",
    "   \n",
    "   return features_df, summary_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923920d8",
   "metadata": {},
   "source": [
    "##### STEP 2: Equation Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "69ea3397",
   "metadata": {},
   "outputs": [],
   "source": [
    "EQUATION_COMPARISON_PROMPT = \"\"\"\n",
    "You are an expert in mathematical notation and ODE systems. Compare these two ODE systems and identify ALL differences with high precision.\n",
    "\n",
    "CORRECT ODE SYSTEM:\n",
    "{correct_system}\n",
    "\n",
    "EXTRACTED ODE SYSTEM:\n",
    "{extracted_system}\n",
    "\n",
    "Analyze the systems for:\n",
    "1. Mathematical equivalence (same mathematical meaning despite notation differences)\n",
    "2. Symbol accuracy (Greek letters, subscripts, superscripts)\n",
    "3. Structural integrity (derivatives, fractions, matrices)\n",
    "4. Completeness (missing equations, terms, or conditions)\n",
    "5. Notation consistency (derivative notation, function notation)\n",
    "\n",
    "Return a structured JSON response:\n",
    "{{\n",
    "    \"mathematically_equivalent\": true/false,\n",
    "    \"comparison_summary\": {{\n",
    "        \"total_equations_correct\": integer,\n",
    "        \"total_equations_extracted\": integer,\n",
    "        \"completely_correct_equations\": integer,\n",
    "        \"partially_correct_equations\": integer,\n",
    "        \"missing_equations\": integer,\n",
    "        \"extra_equations\": integer\n",
    "    }},\n",
    "    \"errors\": [\n",
    "        {{\n",
    "            \"equation_index\": integer,\n",
    "            \"error_description\": \"specific description\",\n",
    "            \"correct_form\": \"what it should be\",\n",
    "            \"extracted_form\": \"what was extracted\",\n",
    "            \"error_location\": \"specific location in equation\"\n",
    "        }}\n",
    "    ],\n",
    "    \"notation_issues\": [\n",
    "        {{\n",
    "            \"type\": \"greek_letter|subscript|superscript|derivative|operator\",\n",
    "            \"details\": \"specific notation problem\"\n",
    "        }}\n",
    "    ]\n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "ERROR_CATEGORIZATION_PROMPT = \"\"\"\n",
    "You are an expert in analyzing mathematical extraction errors. Categorize the errors from the equation comparison.\n",
    "\n",
    "COMPARISON RESULTS:\n",
    "{comparison_results}\n",
    "\n",
    "Analyze and categorize each error based on:\n",
    "\n",
    "1. ERROR CATEGORIES:\n",
    "   - symbol_recognition: Greek letters, special mathematical symbols misrecognized\n",
    "   - subscript_superscript: Issues with sub/superscript notation\n",
    "   - structural_corruption: Fractions, matrices, nested structures damaged\n",
    "   - derivative_notation: Problems with derivative representations\n",
    "   - boundary_initial_conditions: Missing or corrupted conditions\n",
    "   - operator_errors: Mathematical operators (+, -, ×, ÷) misrecognized\n",
    "   - completeness_errors: Missing equations, terms, or parts\n",
    "   - formatting_errors: Layout, alignment, multi-line equation issues\n",
    "\n",
    "2. SEVERITY LEVELS:\n",
    "   - low: Cosmetic issues that don't affect mathematical meaning\n",
    "   - medium: Errors that make equations harder to read but still understandable\n",
    "   - high: Significant errors affecting mathematical correctness\n",
    "   - critical: Errors making equations unusable or mathematically wrong\n",
    "\n",
    "3. ROOT CAUSES:\n",
    "   - ocr_limitation: Typical OCR challenges (similar looking characters)\n",
    "   - complexity_induced: Errors due to equation complexity\n",
    "   - notation_ambiguity: Unclear or ambiguous notation in source\n",
    "   - extraction_logic: Issues with the extraction algorithm\n",
    "\n",
    "Return structured JSON:\n",
    "{{\n",
    "    \"overall_severity\": \"low|medium|high|critical\",\n",
    "    \"primary_error_category\": \"most common category\",\n",
    "    \"error_distribution\": {{\n",
    "        \"by_category\": {{\n",
    "            \"symbol_recognition\": integer,\n",
    "            \"subscript_superscript\": integer,\n",
    "            ...\n",
    "        }},\n",
    "        \"by_severity\": {{\n",
    "            \"low\": integer,\n",
    "            \"medium\": integer,\n",
    "            \"high\": integer,\n",
    "            \"critical\": integer\n",
    "        }}\n",
    "    }},\n",
    "    \"detailed_categorization\": [\n",
    "        {{\n",
    "            \"error_id\": integer,\n",
    "            \"categories\": [\"primary_category\", \"secondary_category\"],\n",
    "            \"severity\": \"low|medium|high|critical\",\n",
    "            \"root_cause\": \"identified cause\",\n",
    "            \"fix_difficulty\": \"easy|moderate|hard\",\n",
    "            \"suggested_improvement\": \"specific suggestion for MIRA\"\n",
    "        }}\n",
    "    ],\n",
    "    \"patterns_identified\": [\n",
    "        {{\n",
    "            \"pattern\": \"description of recurring error pattern\",\n",
    "            \"frequency\": integer,\n",
    "            \"affected_features\": [\"list of equation features that correlate with this error\"]\n",
    "        }}\n",
    "    ],\n",
    "    \"extraction_quality_score\": float (0-100)\n",
    "}}\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a1e1db81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_openai_completion(prompt, model=\"gpt-4\", temperature=0.0, max_tokens=1024):\n",
    "    \"\"\"Send prompt to OpenAI API\"\"\"\n",
    "    try:\n",
    "        response = client.chat.completions.create(  \n",
    "            model=model,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=temperature,\n",
    "            max_tokens=max_tokens,\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        print(f\"OpenAI API error: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "181f63cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_equation_string(eq_str):\n",
    "    \"\"\"Clean equation string from CSV format\"\"\"\n",
    "    if pd.isna(eq_str):\n",
    "        return None\n",
    "    \n",
    "    eq_str = str(eq_str)\n",
    "    \n",
    "    # YOUR SPECIFIC CASE: starts with '\" and ends with )\"\n",
    "    # Check for single quote followed by double quote\n",
    "    if len(eq_str) >= 2 and eq_str[0] == \"'\" and eq_str[1] == '\"':\n",
    "        eq_str = eq_str[2:]  # Remove '\"\n",
    "    elif eq_str.startswith('\"'):\n",
    "        eq_str = eq_str[1:]  # Remove just \"\n",
    "    \n",
    "    # Remove the trailing patterns\n",
    "    if eq_str.endswith(')\"'):\n",
    "        eq_str = eq_str[:-2]  # Remove )\"\n",
    "    elif eq_str.endswith('\"'):\n",
    "        eq_str = eq_str[:-1]  # Remove just \"\n",
    "    elif eq_str.endswith(\"'\"):\n",
    "        eq_str = eq_str[:-1]  # Remove just '\n",
    "    \n",
    "    # Clean up escapes\n",
    "    eq_str = eq_str.replace('\\\\n', '\\n')\n",
    "    eq_str = eq_str.replace('\\\\\"', '\"')\n",
    "    eq_str = eq_str.replace(\"\\\\\\'\", \"'\")\n",
    "    \n",
    "    return eq_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "140baec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_ode_system(model, correct_df, extracted_df, version=VERSION):\n",
    "    \"\"\"Compare ODE systems using OpenAI\"\"\"\n",
    "    \n",
    "    # getting the ODE systems\n",
    "    correct_system = correct_df[correct_df['model'] == model]['correct_eqs'].values\n",
    "    if len(correct_system) == 0:\n",
    "        print(f\"No correct equation found for {model}\")\n",
    "        return None\n",
    "    correct_system = correct_system[0]\n",
    "    \n",
    "    # No version filtering needed - just get by model\n",
    "    extracted_row = extracted_df[extracted_df['model'] == model]\n",
    "    \n",
    "    if len(extracted_row) == 0:\n",
    "        print(f\"No extraction found for {model}\")\n",
    "        return None\n",
    "    \n",
    "    extracted_system = extracted_row['extracted_eqs'].values[0]\n",
    "    \n",
    "    # Check for None (was NaN)\n",
    "    if correct_system is None or extracted_system is None:\n",
    "        print(f\"Missing equation data for {model}\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"\\nComparing equations for {model}\")\n",
    "    print(f\"Correct equation length: {len(correct_system)} chars\")\n",
    "    print(f\"Extracted equation length: {len(extracted_system)} chars\")\n",
    "    \n",
    "    # prompt\n",
    "    formatted_prompt = EQUATION_COMPARISON_PROMPT.format(\n",
    "        correct_system=correct_system,\n",
    "        extracted_system=extracted_system\n",
    "    )\n",
    "    \n",
    "    # send to OpenAI\n",
    "    try:\n",
    "        response = get_openai_completion(formatted_prompt, temperature=0.0, max_tokens=2048)\n",
    "        \n",
    "        if response:\n",
    "            # DEBUG show response\n",
    "            print(f\"\\nDEBUG - OpenAI response (first 200 chars): {response[:200]}\")\n",
    "            \n",
    "            result = json.loads(response)\n",
    "            \n",
    "            print(f\"\\nModel: {model}\")\n",
    "            print(\"=\"*50)\n",
    "            print(f\"Mathematically equivalent: {result['mathematically_equivalent']}\")\n",
    "            \n",
    "            if result.get('errors'):\n",
    "                print(f\"\\nErrors found ({len(result['errors'])}):\") \n",
    "                for i, error in enumerate(result['errors'], 1):\n",
    "                    print(f\"  {i}. {error.get('error_description', 'No description')}\")\n",
    "            else:\n",
    "                print(\"\\nNo errors - perfect extraction!\")\n",
    "            \n",
    "            return result\n",
    "            \n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error parsing JSON response: {e}\")\n",
    "        print(f\"Raw response: {response}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error in comparison: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81fd6eb",
   "metadata": {},
   "source": [
    "##### STEP3: Categorizing the errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0d4529a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def step3_ai_categorize_errors(model, step2_result):\n",
    "    \"\"\"Categorize errors using OpenAI\"\"\"\n",
    "    \n",
    "    if not step2_result or not step2_result.get('errors'):\n",
    "        return {\n",
    "            'model': model,\n",
    "            'overall_severity': 'none',\n",
    "            'primary_error_category': 'perfect_extraction',\n",
    "            'error_distribution': {'by_category': {}, 'by_severity': {'none': 1}},\n",
    "            'detailed_categorization': [],\n",
    "            'patterns_identified': [],\n",
    "            'extraction_quality_score': 100.0\n",
    "        }\n",
    "    \n",
    "    # prepare comparison results for categorization\n",
    "    comparison_data = {\n",
    "        'model': model,\n",
    "        'errors': step2_result.get('errors', []),\n",
    "        'notation_issues': step2_result.get('notation_issues', []),\n",
    "        'summary': step2_result.get('comparison_summary', {})\n",
    "    }\n",
    "    \n",
    "    # prompt\n",
    "    formatted_prompt = ERROR_CATEGORIZATION_PROMPT.format(\n",
    "        comparison_results=json.dumps(comparison_data, indent=2)\n",
    "    )\n",
    "    \n",
    "    # send to OpenAI\n",
    "    response = get_openai_completion(formatted_prompt, temperature=0.0, max_tokens=1024)\n",
    "    \n",
    "    if response:\n",
    "        try:\n",
    "            categorization = json.loads(response)\n",
    "            categorization['model'] = model\n",
    "            categorization['total_errors'] = len(step2_result.get('errors', []))\n",
    "            \n",
    "            # Print results\n",
    "            print(f\"\\nERROR CATEGORIZATION: {model}\")\n",
    "            print(\"=\"*50)\n",
    "            print(f\"Overall Severity: {categorization.get('overall_severity', 'unknown')}\")\n",
    "            print(f\"Primary Category: {categorization.get('primary_error_category', 'unknown')}\")\n",
    "            print(f\"Quality Score: {categorization.get('extraction_quality_score', 0)}/100\")\n",
    "            \n",
    "            if categorization.get('error_distribution'):\n",
    "                print(\"\\nError Distribution by Category:\")\n",
    "                for category, count in categorization['error_distribution'].get('by_category', {}).items():\n",
    "                    print(f\"  {category}: {count}\")\n",
    "            \n",
    "            return categorization\n",
    "            \n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error parsing JSON response: {e}\")\n",
    "            print(f\"Raw response: {response}\")\n",
    "            return None\n",
    "    \n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a75bff7",
   "metadata": {},
   "source": [
    "Main Execution Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9956171f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_complete_analysis(correct_df, extracted_df, version=VERSION, models_to_analyze=None):\n",
    "    \"\"\"Run the complete error analysis pipeline\n",
    "    \n",
    "    Args:\n",
    "        correct_df: DataFrame with correct equations\n",
    "        extracted_df: DataFrame with extracted equations  \n",
    "        version: Version string to filter extracted equations\n",
    "        models_to_analyze: List of specific models to analyze, or None for all\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"STEP 1: Extracting Features...\")\n",
    "    features_df = step1_extract_and_score_features(correct_df)\n",
    "    \n",
    "    print(\"\\nSTEP 2 & 3: Comparing and Categorizing...\")\n",
    "    comparison_results = []\n",
    "    categorization_results = []\n",
    "    \n",
    "    # get models to process\n",
    "    if models_to_analyze is not None:\n",
    "        models = models_to_analyze\n",
    "    else:\n",
    "        models = correct_df['model'].unique()\n",
    "    \n",
    "    print(f\"Will analyze {len(models)} models\")\n",
    "    \n",
    "    # Process each model\n",
    "    for i, model in enumerate(models):\n",
    "        print(f\"\\n[{i+1}/{len(models)}] Processing {model}...\")\n",
    "        \n",
    "        step2_result = compare_ode_system(model, correct_df, extracted_df, version)\n",
    "        \n",
    "        if step2_result:\n",
    "            comparison_results.append({\n",
    "                'model': model,\n",
    "                'result': step2_result\n",
    "            })\n",
    "            \n",
    "            step3_result = step3_ai_categorize_errors(model, step2_result)\n",
    "            \n",
    "            if step3_result:\n",
    "                categorization_results.append(step3_result)\n",
    "        \n",
    "        time.sleep(1)\n",
    "    \n",
    "    # creating summary df\n",
    "    summary_data = []\n",
    "    for comp, cat in zip(comparison_results, categorization_results):\n",
    "        row = {\n",
    "            'model': comp['model'],\n",
    "            'mathematically_equivalent': comp['result'].get('mathematically_equivalent', False),\n",
    "            'total_errors': len(comp['result'].get('errors', [])),\n",
    "            'overall_severity': cat.get('overall_severity', 'unknown'),\n",
    "            'primary_error_category': cat.get('primary_error_category', 'unknown'),\n",
    "            'quality_score': cat.get('extraction_quality_score', 0)\n",
    "        }\n",
    "        summary_data.append(row)\n",
    "    \n",
    "    summary_df = pd.DataFrame(summary_data)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ANALYSIS COMPLETE\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Models analyzed: {len(summary_df)}\")\n",
    "    if len(summary_df) > 0:\n",
    "        print(f\"Perfect extractions: {summary_df['mathematically_equivalent'].sum()}\")\n",
    "        print(f\"Average quality score: {summary_df['quality_score'].mean():.1f}/100\")\n",
    "    \n",
    "    return features_df, comparison_results, categorization_results, summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d2a1ea49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_models_for_analysis(correct_df, extracted_df, version=VERSION):\n",
    "    \"\"\"Get models that exist in both correct and extracted dataframes for a given version\"\"\"\n",
    "    \n",
    "    # Get models from correct equations\n",
    "    correct_models = set(correct_df['model'].dropna().unique())\n",
    "    \n",
    "    # Get models from extracted equations (no version filtering needed)\n",
    "    extracted_models = set(extracted_df['model'].dropna().unique())\n",
    "    \n",
    "    # Find intersection - models that exist in both\n",
    "    common_models = correct_models.intersection(extracted_models)\n",
    "    \n",
    "    print(f\"Models in correct_eqs: {len(correct_models)}\")\n",
    "    print(f\"Models in extracted_eqs (from {version} file): {len(extracted_models)}\")\n",
    "    print(f\"Common models to analyze: {len(common_models)}\")\n",
    "    \n",
    "    if len(common_models) == 0:\n",
    "        print(\"\\nNo common models found!\")\n",
    "        print(\"Sample correct models:\", list(correct_models)[:5])\n",
    "        print(\"Sample extracted models:\", list(extracted_models)[:5])\n",
    "    \n",
    "    return list(common_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e21b07",
   "metadata": {},
   "source": [
    "#### Execution of the steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "197ec40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# master csv for results\n",
    "def append_to_master_results(analysis_results, version=VERSION, master_file='master_analysis_results.csv'):\n",
    "    \"\"\"Append current analysis results to a master CSV file\"\"\"\n",
    "    # [Insert the full append_to_master_results function code here]\n",
    "\n",
    "def create_analysis_summary_report(master_file='master_analysis_results.csv'):\n",
    "    \"\"\"Create a summary report from the master results file\"\"\"\n",
    "    # [Insert the full create_analysis_summary_report function code here]\n",
    "\n",
    "def run_and_append_analysis(correct_df, extracted_df, version=VERSION, models_to_analyze=None):\n",
    "    \"\"\"Run analysis and append to master file - convenience function\"\"\"\n",
    "    # [Insert the full run_and_append_analysis function code here]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "315924b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API key found!\n",
      "\n",
      "Analyzing models from version: 001\n",
      "============================================================\n",
      "Models in correct_eqs: 10\n",
      "Models in extracted_eqs (from 001 file): 10\n",
      "Common models to analyze: 10\n",
      "\n",
      "Starting Error Analysis Pipeline for 10 models...\n",
      "============================================================\n",
      "STEP 1: Extracting Features...\n",
      "\n",
      " Feature Extraction Summary\n",
      "==================================================\n",
      "Total equations analyzed: 10\n",
      "\n",
      "Complexity Score Distribution:\n",
      "  Low (0-3): 0\n",
      "  Medium (3-6): 7\n",
      "  High (6-8): 3\n",
      "  Very High (8-10): 0\n",
      "\n",
      "Risk Categories:\n",
      "risk_category\n",
      "high         5\n",
      "very_high    5\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Top 5 Most Complex Equations:\n",
      "                    model  overall_complexity_score risk_category\n",
      "7  2024_dec_epi_1_model_B                  6.876132     very_high\n",
      "6  2024_dec_epi_1_model_A                  6.807692     very_high\n",
      "8  2024_dec_epi_1_model_C                  6.174147     very_high\n",
      "3         BIOMD0000000958                  5.861461     very_high\n",
      "4         BIOMD0000000960                  5.658621     very_high\n",
      "\n",
      "Feature Statistics:\n",
      "  Equations with Greek letters: 0 (0.0%)\n",
      "  Equations with subscripts: 6 (60.0%)\n",
      "  Multi-line equations: 10 (100.0%)\n",
      "  Average ODE order: 1.00\n",
      "  Average complexity indicators per equation: 2.90\n",
      "\n",
      "STEP 2 & 3: Comparing and Categorizing...\n",
      "Will analyze 10 models\n",
      "\n",
      "[1/10] Processing BIOMD0000000960...\n",
      "\n",
      "Comparing equations for BIOMD0000000960\n",
      "Correct equation length: 580 chars\n",
      "Extracted equation length: 590 chars\n",
      "\n",
      "DEBUG - OpenAI response (first 200 chars): {\n",
      "    \"mathematically_equivalent\": false,\n",
      "    \"comparison_summary\": {\n",
      "        \"total_equations_correct\": 7,\n",
      "        \"total_equations_extracted\": 7,\n",
      "        \"completely_correct_equations\": 2,\n",
      "        \"\n",
      "\n",
      "Model: BIOMD0000000960\n",
      "==================================================\n",
      "Mathematically equivalent: False\n",
      "\n",
      "Errors found (4):\n",
      "  1. Incorrect coefficients in the equation\n",
      "  2. Incorrect coefficient in the equation\n",
      "  3. Incorrect coefficient in the equation\n",
      "  4. Incorrect coefficient in the equation\n",
      "\n",
      "ERROR CATEGORIZATION: BIOMD0000000960\n",
      "==================================================\n",
      "Overall Severity: high\n",
      "Primary Category: symbol_recognition\n",
      "Quality Score: 60.0/100\n",
      "\n",
      "Error Distribution by Category:\n",
      "  symbol_recognition: 4\n",
      "  subscript_superscript: 1\n",
      "  structural_corruption: 0\n",
      "  derivative_notation: 0\n",
      "  boundary_initial_conditions: 0\n",
      "  operator_errors: 1\n",
      "  completeness_errors: 0\n",
      "  formatting_errors: 0\n",
      "\n",
      "[2/10] Processing BIOMD0000000955...\n",
      "\n",
      "Comparing equations for BIOMD0000000955\n",
      "Correct equation length: 662 chars\n",
      "Extracted equation length: 660 chars\n",
      "\n",
      "DEBUG - OpenAI response (first 200 chars): The two ODE systems are identical. Therefore, they are mathematically equivalent, symbol accuracy is maintained, structural integrity is preserved, completeness is ensured, and notation consistency is\n",
      "Error parsing JSON response: Expecting value: line 1 column 1 (char 0)\n",
      "Raw response: The two ODE systems are identical. Therefore, they are mathematically equivalent, symbol accuracy is maintained, structural integrity is preserved, completeness is ensured, and notation consistency is upheld. \n",
      "\n",
      "Here is the structured JSON response:\n",
      "\n",
      "{\n",
      "    \"mathematically_equivalent\": true,\n",
      "    \"comparison_summary\": {\n",
      "        \"total_equations_correct\": 8,\n",
      "        \"total_equations_extracted\": 8,\n",
      "        \"completely_correct_equations\": 8,\n",
      "        \"partially_correct_equations\": 0,\n",
      "        \"missing_equations\": 0,\n",
      "        \"extra_equations\": 0\n",
      "    },\n",
      "    \"errors\": [],\n",
      "    \"notation_issues\": []\n",
      "}\n",
      "\n",
      "[3/10] Processing BIOMD0000000958...\n",
      "\n",
      "Comparing equations for BIOMD0000000958\n",
      "Correct equation length: 746 chars\n",
      "Extracted equation length: 699 chars\n",
      "\n",
      "DEBUG - OpenAI response (first 200 chars): {\n",
      "    \"mathematically_equivalent\": false,\n",
      "    \"comparison_summary\": {\n",
      "        \"total_equations_correct\": 8,\n",
      "        \"total_equations_extracted\": 8,\n",
      "        \"completely_correct_equations\": 0,\n",
      "        \"\n",
      "\n",
      "Model: BIOMD0000000958\n",
      "==================================================\n",
      "Mathematically equivalent: False\n",
      "\n",
      "Errors found (6):\n",
      "  1. Missing division by N in the last term\n",
      "  2. Incorrect kappa symbol\n",
      "  3. Incorrect kappa symbol\n",
      "  4. Incorrect kappa symbol\n",
      "  5. Missing rho2 in the term\n",
      "  6. Incorrect multiplication with H(t)\n",
      "\n",
      "ERROR CATEGORIZATION: BIOMD0000000958\n",
      "==================================================\n",
      "Overall Severity: high\n",
      "Primary Category: symbol_recognition\n",
      "Quality Score: 60.0/100\n",
      "\n",
      "Error Distribution by Category:\n",
      "  symbol_recognition: 4\n",
      "  subscript_superscript: 0\n",
      "  structural_corruption: 0\n",
      "  derivative_notation: 0\n",
      "  boundary_initial_conditions: 0\n",
      "  operator_errors: 2\n",
      "  completeness_errors: 1\n",
      "  formatting_errors: 0\n",
      "\n",
      "[4/10] Processing BIOMD0000000956...\n",
      "\n",
      "Comparing equations for BIOMD0000000956\n",
      "Correct equation length: 229 chars\n",
      "Extracted equation length: 235 chars\n",
      "\n",
      "DEBUG - OpenAI response (first 200 chars): {\n",
      "    \"mathematically_equivalent\": false,\n",
      "    \"comparison_summary\": {\n",
      "        \"total_equations_correct\": 4,\n",
      "        \"total_equations_extracted\": 4,\n",
      "        \"completely_correct_equations\": 2,\n",
      "        \"\n",
      "\n",
      "Model: BIOMD0000000956\n",
      "==================================================\n",
      "Mathematically equivalent: False\n",
      "\n",
      "Errors found (2):\n",
      "  1. Incorrect use of function N(t) instead of constant N\n",
      "  2. Incorrect use of function N(t) instead of constant N\n",
      "\n",
      "ERROR CATEGORIZATION: BIOMD0000000956\n",
      "==================================================\n",
      "Overall Severity: high\n",
      "Primary Category: symbol_recognition\n",
      "Quality Score: 50.0/100\n",
      "\n",
      "Error Distribution by Category:\n",
      "  symbol_recognition: 2\n",
      "  subscript_superscript: 0\n",
      "  structural_corruption: 0\n",
      "  derivative_notation: 0\n",
      "  boundary_initial_conditions: 0\n",
      "  operator_errors: 0\n",
      "  completeness_errors: 0\n",
      "  formatting_errors: 0\n",
      "\n",
      "[5/10] Processing BIOMD0000000962...\n",
      "\n",
      "Comparing equations for BIOMD0000000962\n",
      "Correct equation length: 276 chars\n",
      "Extracted equation length: 276 chars\n",
      "\n",
      "DEBUG - OpenAI response (first 200 chars): {\n",
      "    \"mathematically_equivalent\": false,\n",
      "    \"comparison_summary\": {\n",
      "        \"total_equations_correct\": 4,\n",
      "        \"total_equations_extracted\": 4,\n",
      "        \"completely_correct_equations\": 3,\n",
      "        \"\n",
      "\n",
      "Model: BIOMD0000000962\n",
      "==================================================\n",
      "Mathematically equivalent: False\n",
      "\n",
      "Errors found (1):\n",
      "  1. In the second equation, the extracted system uses U(0) and S(0) instead of U(t) and S(t) in the multiplication term.\n",
      "\n",
      "ERROR CATEGORIZATION: BIOMD0000000962\n",
      "==================================================\n",
      "Overall Severity: high\n",
      "Primary Category: boundary_initial_conditions\n",
      "Quality Score: 75.0/100\n",
      "\n",
      "Error Distribution by Category:\n",
      "  symbol_recognition: 0\n",
      "  subscript_superscript: 0\n",
      "  structural_corruption: 0\n",
      "  derivative_notation: 0\n",
      "  boundary_initial_conditions: 1\n",
      "  operator_errors: 0\n",
      "  completeness_errors: 0\n",
      "  formatting_errors: 0\n",
      "\n",
      "[6/10] Processing 2024_dec_epi_1_model_B...\n",
      "\n",
      "Comparing equations for 2024_dec_epi_1_model_B\n",
      "Correct equation length: 729 chars\n",
      "Extracted equation length: 676 chars\n",
      "\n",
      "DEBUG - OpenAI response (first 200 chars): {\n",
      "    \"mathematically_equivalent\": false,\n",
      "    \"comparison_summary\": {\n",
      "        \"total_equations_correct\": 8,\n",
      "        \"total_equations_extracted\": 8,\n",
      "        \"completely_correct_equations\": 0,\n",
      "        \"\n",
      "\n",
      "Model: 2024_dec_epi_1_model_B\n",
      "==================================================\n",
      "Mathematically equivalent: False\n",
      "\n",
      "Errors found (5):\n",
      "  1. Missing term in the equation\n",
      "  2. Incorrect term in the equation\n",
      "  3. Incorrect term in the equation\n",
      "  4. Incorrect term in the equation\n",
      "  5. Incorrect term in the equation\n",
      "\n",
      "ERROR CATEGORIZATION: 2024_dec_epi_1_model_B\n",
      "==================================================\n",
      "Overall Severity: high\n",
      "Primary Category: symbol_recognition\n",
      "Quality Score: 60.0/100\n",
      "\n",
      "Error Distribution by Category:\n",
      "  symbol_recognition: 4\n",
      "  subscript_superscript: 2\n",
      "  structural_corruption: 0\n",
      "  derivative_notation: 0\n",
      "  boundary_initial_conditions: 0\n",
      "  operator_errors: 0\n",
      "  completeness_errors: 1\n",
      "  formatting_errors: 0\n",
      "\n",
      "[7/10] Processing BIOMD0000000957...\n",
      "\n",
      "Comparing equations for BIOMD0000000957\n",
      "Correct equation length: 239 chars\n",
      "Extracted equation length: 239 chars\n",
      "\n",
      "DEBUG - OpenAI response (first 200 chars): {\n",
      "    \"mathematically_equivalent\": true,\n",
      "    \"comparison_summary\": {\n",
      "        \"total_equations_correct\": 4,\n",
      "        \"total_equations_extracted\": 4,\n",
      "        \"completely_correct_equations\": 4,\n",
      "        \"p\n",
      "\n",
      "Model: BIOMD0000000957\n",
      "==================================================\n",
      "Mathematically equivalent: True\n",
      "\n",
      "No errors - perfect extraction!\n",
      "\n",
      "[8/10] Processing 2024_dec_epi_1_model_A...\n",
      "\n",
      "Comparing equations for 2024_dec_epi_1_model_A\n",
      "Correct equation length: 962 chars\n",
      "Extracted equation length: 1037 chars\n",
      "\n",
      "DEBUG - OpenAI response (first 200 chars): {\n",
      "    \"mathematically_equivalent\": false,\n",
      "    \"comparison_summary\": {\n",
      "        \"total_equations_correct\": 12,\n",
      "        \"total_equations_extracted\": 14,\n",
      "        \"completely_correct_equations\": 1,\n",
      "       \n",
      "\n",
      "Model: 2024_dec_epi_1_model_A\n",
      "==================================================\n",
      "Mathematically equivalent: False\n",
      "\n",
      "Errors found (13):\n",
      "  1. Incorrect constant in the equation\n",
      "  2. Incorrect multiplication with rho\n",
      "  3. Incorrect variable and missing multiplication\n",
      "  4. Incorrect terms in the equation\n",
      "  5. Incorrect terms in the equation\n",
      "  6. Incorrect multiplication and missing terms\n",
      "  7. Missing term in the equation\n",
      "  8. Incorrect variable names and constants\n",
      "  9. Incorrect variable names\n",
      "  10. Incorrect variable names\n",
      "  11. Incorrect variable names\n",
      "  12. Extra equation\n",
      "  13. Extra equation\n",
      "Error parsing JSON response: Unterminated string starting at: line 123 column 27 (char 4518)\n",
      "Raw response: {\n",
      "    \"overall_severity\": \"high\",\n",
      "    \"primary_error_category\": \"symbol_recognition\",\n",
      "    \"error_distribution\": {\n",
      "        \"by_category\": {\n",
      "            \"symbol_recognition\": 5,\n",
      "            \"subscript_superscript\": 4,\n",
      "            \"structural_corruption\": 0,\n",
      "            \"derivative_notation\": 0,\n",
      "            \"boundary_initial_conditions\": 0,\n",
      "            \"operator_errors\": 3,\n",
      "            \"completeness_errors\": 4,\n",
      "            \"formatting_errors\": 0\n",
      "        },\n",
      "        \"by_severity\": {\n",
      "            \"low\": 0,\n",
      "            \"medium\": 4,\n",
      "            \"high\": 8,\n",
      "            \"critical\": 2\n",
      "        }\n",
      "    },\n",
      "    \"detailed_categorization\": [\n",
      "        {\n",
      "            \"error_id\": 1,\n",
      "            \"categories\": [\"symbol_recognition\"],\n",
      "            \"severity\": \"medium\",\n",
      "            \"root_cause\": \"ocr_limitation\",\n",
      "            \"fix_difficulty\": \"easy\",\n",
      "            \"suggested_improvement\": \"Improve recognition of Greek letters\"\n",
      "        },\n",
      "        {\n",
      "            \"error_id\": 2,\n",
      "            \"categories\": [\"operator_errors\"],\n",
      "            \"severity\": \"high\",\n",
      "            \"root_cause\": \"extraction_logic\",\n",
      "            \"fix_difficulty\": \"moderate\",\n",
      "            \"suggested_improvement\": \"Improve handling of multiplication operations\"\n",
      "        },\n",
      "        {\n",
      "            \"error_id\": 3,\n",
      "            \"categories\": [\"symbol_recognition\"],\n",
      "            \"severity\": \"medium\",\n",
      "            \"root_cause\": \"ocr_limitation\",\n",
      "            \"fix_difficulty\": \"easy\",\n",
      "            \"suggested_improvement\": \"Improve recognition of Greek letters\"\n",
      "        },\n",
      "        {\n",
      "            \"error_id\": 4,\n",
      "            \"categories\": [\"completeness_errors\"],\n",
      "            \"severity\": \"high\",\n",
      "            \"root_cause\": \"extraction_logic\",\n",
      "            \"fix_difficulty\": \"hard\",\n",
      "            \"suggested_improvement\": \"Improve extraction of complex terms\"\n",
      "        },\n",
      "        {\n",
      "            \"error_id\": 5,\n",
      "            \"categories\": [\"completeness_errors\", \"operator_errors\"],\n",
      "            \"severity\": \"high\",\n",
      "            \"root_cause\": \"extraction_logic\",\n",
      "            \"fix_difficulty\": \"hard\",\n",
      "            \"suggested_improvement\": \"Improve extraction of complex terms and operations\"\n",
      "        },\n",
      "        {\n",
      "            \"error_id\": 6,\n",
      "            \"categories\": [\"operator_errors\", \"completeness_errors\"],\n",
      "            \"severity\": \"high\",\n",
      "            \"root_cause\": \"extraction_logic\",\n",
      "            \"fix_difficulty\": \"hard\",\n",
      "            \"suggested_improvement\": \"Improve extraction of complex terms and operations\"\n",
      "        },\n",
      "        {\n",
      "            \"error_id\": 7,\n",
      "            \"categories\": [\"completeness_errors\"],\n",
      "            \"severity\": \"high\",\n",
      "            \"root_cause\": \"extraction_logic\",\n",
      "            \"fix_difficulty\": \"hard\",\n",
      "            \"suggested_improvement\": \"Improve extraction of complex terms\"\n",
      "        },\n",
      "        {\n",
      "            \"error_id\": 8,\n",
      "            \"categories\": [\"symbol_recognition\", \"subscript_superscript\"],\n",
      "            \"severity\": \"high\",\n",
      "            \"root_cause\": \"ocr_limitation\",\n",
      "            \"fix_difficulty\": \"moderate\",\n",
      "            \"suggested_improvement\": \"Improve recognition of variable names and subscripts\"\n",
      "        },\n",
      "        {\n",
      "            \"error_id\": 9,\n",
      "            \"categories\": [\"symbol_recognition\", \"subscript_superscript\"],\n",
      "            \"severity\": \"high\",\n",
      "            \"root_cause\": \"ocr_limitation\",\n",
      "            \"fix_difficulty\": \"moderate\",\n",
      "            \"suggested_improvement\": \"Improve recognition of variable names and subscripts\"\n",
      "        },\n",
      "        {\n",
      "            \"error_id\": 10,\n",
      "            \"categories\": [\"symbol_recognition\", \"subscript_superscript\"],\n",
      "            \"severity\": \"high\",\n",
      "            \"root_cause\": \"ocr_limitation\",\n",
      "            \"fix_difficulty\": \"moderate\",\n",
      "            \"suggested_improvement\": \"Improve recognition of variable names and subscripts\"\n",
      "        },\n",
      "        {\n",
      "            \"error_id\": 11,\n",
      "            \"categories\": [\"symbol_recognition\", \"subscript_superscript\"],\n",
      "            \"severity\": \"high\",\n",
      "            \"root_cause\": \"ocr_limitation\",\n",
      "            \"fix_difficulty\": \"moderate\",\n",
      "            \"suggested_improvement\": \"Improve recognition of variable names and subscripts\"\n",
      "        },\n",
      "        {\n",
      "            \"error_id\": 12,\n",
      "            \"categories\": [\"completeness_errors\"],\n",
      "            \"severity\": \"critical\",\n",
      "            \"root_cause\": \"extraction_logic\",\n",
      "            \"fix_difficulty\": \"hard\",\n",
      "            \"suggested_improvement\": \"Improve detection of extra equations\"\n",
      "        },\n",
      "        {\n",
      "            \"error_id\": 13,\n",
      "            \"categories\": [\"completeness_errors\"],\n",
      "            \"severity\": \"critical\",\n",
      "            \"root_cause\": \"extraction_logic\n",
      "\n",
      "[9/10] Processing SAPHIRE...\n",
      "\n",
      "Comparing equations for SAPHIRE\n",
      "Correct equation length: 542 chars\n",
      "Extracted equation length: 540 chars\n",
      "\n",
      "DEBUG - OpenAI response (first 200 chars): {\n",
      "    \"mathematically_equivalent\": false,\n",
      "    \"comparison_summary\": {\n",
      "        \"total_equations_correct\": 7,\n",
      "        \"total_equations_extracted\": 7,\n",
      "        \"completely_correct_equations\": 6,\n",
      "        \"\n",
      "\n",
      "Model: SAPHIRE\n",
      "==================================================\n",
      "Mathematically equivalent: False\n",
      "\n",
      "Errors found (1):\n",
      "  1. Missing division by N in the third term of the equation\n",
      "\n",
      "ERROR CATEGORIZATION: SAPHIRE\n",
      "==================================================\n",
      "Overall Severity: high\n",
      "Primary Category: completeness_errors\n",
      "Quality Score: 85.7/100\n",
      "\n",
      "Error Distribution by Category:\n",
      "  symbol_recognition: 0\n",
      "  subscript_superscript: 0\n",
      "  structural_corruption: 0\n",
      "  derivative_notation: 0\n",
      "  boundary_initial_conditions: 0\n",
      "  operator_errors: 0\n",
      "  completeness_errors: 1\n",
      "  formatting_errors: 0\n",
      "\n",
      "[10/10] Processing 2024_dec_epi_1_model_C...\n",
      "\n",
      "Comparing equations for 2024_dec_epi_1_model_C\n",
      "Correct equation length: 469 chars\n",
      "Extracted equation length: 469 chars\n",
      "\n",
      "DEBUG - OpenAI response (first 200 chars): The two ODE systems provided are identical. Therefore, they are mathematically equivalent, have the same symbol accuracy, structural integrity, completeness, and notation consistency. \n",
      "\n",
      "Here is the st\n",
      "Error parsing JSON response: Expecting value: line 1 column 1 (char 0)\n",
      "Raw response: The two ODE systems provided are identical. Therefore, they are mathematically equivalent, have the same symbol accuracy, structural integrity, completeness, and notation consistency. \n",
      "\n",
      "Here is the structured JSON response:\n",
      "\n",
      "{\n",
      "    \"mathematically_equivalent\": true,\n",
      "    \"comparison_summary\": {\n",
      "        \"total_equations_correct\": 8,\n",
      "        \"total_equations_extracted\": 8,\n",
      "        \"completely_correct_equations\": 8,\n",
      "        \"partially_correct_equations\": 0,\n",
      "        \"missing_equations\": 0,\n",
      "        \"extra_equations\": 0\n",
      "    },\n",
      "    \"errors\": [],\n",
      "    \"notation_issues\": []\n",
      "}\n",
      "\n",
      "============================================================\n",
      "ANALYSIS COMPLETE\n",
      "============================================================\n",
      "Models analyzed: 7\n",
      "Perfect extractions: 1\n",
      "Average quality score: 70.1/100\n",
      "\n",
      "✓ Analysis complete!\n",
      "\n",
      "Results saved to:\n",
      "  - ./features_analysis_001.csv\n",
      "  - ./error_analysis_summary_001.csv\n",
      "  - ./comparison_results_001.json\n",
      "  - ./categorization_results_001.json\n",
      "\n",
      "Quick Summary:\n",
      "                    model  mathematically_equivalent  total_errors  \\\n",
      "0         BIOMD0000000960                      False             4   \n",
      "1         BIOMD0000000958                      False             6   \n",
      "2         BIOMD0000000956                      False             2   \n",
      "3         BIOMD0000000962                      False             1   \n",
      "4  2024_dec_epi_1_model_B                      False             5   \n",
      "5         BIOMD0000000957                       True             0   \n",
      "6  2024_dec_epi_1_model_A                      False            13   \n",
      "\n",
      "  overall_severity  quality_score  \n",
      "0             high           60.0  \n",
      "1             high           60.0  \n",
      "2             high           50.0  \n",
      "3             high           75.0  \n",
      "4             high           60.0  \n",
      "5             none          100.0  \n",
      "6             high           85.7  \n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # check API key\n",
    "    if not os.getenv(\"OPENAI_API_KEY\"):\n",
    "        print(\"ERROR: OPENAI_API_KEY environment variable not set!\")\n",
    "        print(\"Set it using: export OPENAI_API_KEY='your-api-key-here'\")\n",
    "    else:\n",
    "        print(\"OpenAI API key found!\")\n",
    "        \n",
    "        print(f\"\\nAnalyzing models from version: {VERSION}\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        try:\n",
    "            models_to_analyze = get_models_for_analysis(\n",
    "                correct_eqs_df,\n",
    "                extracted_eqs_df, \n",
    "                version=VERSION\n",
    "            )\n",
    "            \n",
    "            if len(models_to_analyze) == 0:\n",
    "                print(\"\\nNo models to analyze. Checking data integrity...\")\n",
    "                print(\"\\nSample from correct_eqs_df:\")\n",
    "                print(correct_eqs_df[['model', 'correct_eqs']].head())\n",
    "                print(\"\\nSample from extracted_eqs_df:\")\n",
    "                print(extracted_eqs_df[['model', 'extracted_eqs']].head())\n",
    "            else:\n",
    "                print(f\"\\nStarting Error Analysis Pipeline for {len(models_to_analyze)} models...\")\n",
    "                print(\"=\"*60)\n",
    "                \n",
    "                # Run the complete analysis directly\n",
    "                features_df, comparison_results, categorization_results, summary_df = run_complete_analysis(\n",
    "                    correct_eqs_df,\n",
    "                    extracted_eqs_df,\n",
    "                    version=VERSION,\n",
    "                    models_to_analyze=models_to_analyze\n",
    "                )\n",
    "                \n",
    "                print(f\"\\n✓ Analysis complete!\")\n",
    "                \n",
    "                # Save results\n",
    "                if SAVE_RESULTS:\n",
    "                    features_df.to_csv(FEATURES_OUTPUT, index=False)\n",
    "                    summary_df.to_csv(SUMMARY_OUTPUT, index=False)\n",
    "                    \n",
    "                    with open(COMPARISON_OUTPUT, 'w') as f:\n",
    "                        json.dump(comparison_results, f, indent=2)\n",
    "                    \n",
    "                    with open(CATEGORIZATION_OUTPUT, 'w') as f:\n",
    "                        json.dump(categorization_results, f, indent=2)\n",
    "                    \n",
    "                    print(f\"\\nResults saved to:\")\n",
    "                    print(f\"  - {FEATURES_OUTPUT}\")\n",
    "                    print(f\"  - {SUMMARY_OUTPUT}\")\n",
    "                    print(f\"  - {COMPARISON_OUTPUT}\")\n",
    "                    print(f\"  - {CATEGORIZATION_OUTPUT}\")\n",
    "                \n",
    "                # Show summary\n",
    "                if not summary_df.empty:\n",
    "                    print(\"\\nQuick Summary:\")\n",
    "                    print(summary_df[['model', 'mathematically_equivalent', 'total_errors', \n",
    "                                     'overall_severity', 'quality_score']].head(10))\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"\\nError during analysis: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "facbe765",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3c43775d",
   "metadata": {},
   "source": [
    "---\n",
    "Other approaches considered to be incorrect:\n",
    "- **Reference validation against existing databases** is impractical due to inconsistent notation across papers (different symbols for same variables), lack of standardized databases and the context-dependent nature of these mathematical expressions. More effective validation: focusing on internal consistency, dimensional analysis, and alignment with the paper's semantic context rather than external database comparisons.\n",
    ">- egyebek"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
