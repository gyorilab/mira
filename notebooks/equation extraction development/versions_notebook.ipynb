{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65b0cf2f",
   "metadata": {},
   "source": [
    "# Workflow for MIRA equations extractions - notes\n",
    "\n",
    "This notebook outlines ideas for prompting for extracting mathematical equations from PDFs in the MIRA framework.\n",
    "\n",
    "---\n",
    "\n",
    "## One-shot Prompting:\n",
    "The basic workflow of MIRA is a one-shot prompting architecture (let's call this **verison = 001**).\n",
    "\n",
    "\n",
    "Process of the extraction: *'mira/notebooks/llm_extraction.ipynb'*\n",
    "\n",
    "Pipeline: *'mira/sources/sympy_ode/llm_util.py'\n",
    "\n",
    "Prompts: *'mira/sources/sympy_ode/constants.py'*\n",
    "\n",
    "Detailed results can be found in the notebook: *mira_llm_extraction_evaluation.ipynb*\n",
    "\n",
    "---\n",
    "\n",
    "## Iterative promting workflow:\n",
    "**version = 002**\n",
    "\n",
    "To improve the precision of the extraction, an iterative workflow is being introduced, with the following steps:\n",
    "### Agent 1:\n",
    "First, an extraction agent uses the original MIRA process to convert equation images into SymPy code and ground biological concepts. \n",
    "\n",
    "### Agent 2:\n",
    "Then, a validation agent checks the extraction for execution errors (missing imports, undefined variables), parameter consistency issues, and incorrect concept grounding. \n",
    "If errors are found, the validation agent corrects them and the process repeats for up to 3 iterations until all checks pass. \n",
    "\n",
    "This multi-agent approach improves extraction accuracy by catching and fixing common errors that the single-shot method might miss, while maintaining backward compatibility with the existing MIRA codebase.\n",
    "\n",
    "### RESULTS OF IMPLEMENTATION:\n",
    "*Forked version on GitHub: *'fruzsedua/mira/tree/extraction-development'*\n",
    "\n",
    "Examples for each result found in this folder: *'mira/notebooks/equation extraction development/extraction error check/string mismatch check/comparison_results_version002'*\n",
    "\n",
    "Process of the extraction: *'mira/notebooks/llm_extraction.ipynb'* -> **More detalied process**\n",
    "\n",
    "Pipeline: *'mira/sources/sympy_ode/llm_util.py' -> **New functions added**\n",
    "\n",
    "Prompts: *'mira/sources/sympy_ode/constants.py'* -> **Error handling prompt added**\n",
    "**\n",
    "**Image extraction:**\n",
    "- Additional rules added: symmetry, transmission structure, patterns, mathematical structure, parameter consistency, completeness check\n",
    "- Epidemology based rules are just ideas (from Claude) -> *revision needed!*\n",
    "\n",
    "**Error checking and correcting:**\n",
    "- Execution errors are mostly fixed during iteration 1:\n",
    "- Syntax rules for detecting and handling functions/symbols\n",
    "- Handling of imports, utilizing their names precisely\n",
    "- Missing parameters are included\n",
    "\n",
    "- Data cannot be parsed if the output format of the prompt is not aligned with the next function -> exact clarification is added to the prompt\n",
    "- Comparing number of factors to the original (count * operators and variables)\n",
    "- Preserving content between iterations of the error handling prompt\n",
    "- Missing /N fixed\n",
    "\n",
    "**Comparison of the extracted odes added:**\n",
    "- Sympy format matching\n",
    "- Sorting of equations (based on the variable on the LHS) for comparison\n",
    "- Template Model → Mtx odes confuses a lot of information due to multiple formatting steps -> *fix needed!*\n",
    "\n",
    "\n",
    "Error handling multi-agent architecture is part of the tm creation \n",
    "pipeline:\n",
    "\n",
    "**Image → LLM Extraction → Multi-Agent Validation → JSON (corrected ODEs + concepts) → Template Model → Mtx odes**\n",
    "\n",
    "**REMAINING ERRORS:**\n",
    "- Parameter consistency: mostly symbolic differences (e.g. rho_1 vs. rho1), sometimes more serious: e.g. rho vs. q (similar) -> LLM has no info, which one is used, doesn’t know it needs fix\n",
    "- Multiplication vs. addition still gets mixed up sometimes\n",
    "- Semantic compartment mismatches I(t) vs. T(t)-> extra validation needed e.g. linear and \n",
    "- Strengthening of the arithmetic validation is much needed!\n",
    "- Precision of coefficient extraction \n",
    "- Still remains: CodeExecutionError: Error while executing the code: 'Symbol' object is not callable (examples: BIOMD000000972, BIOMD000000976)\n",
    "- The error handling function  mixes up the order of operations in some cases (example: BIOMD0000000991)\n",
    "- Extraction of the compartments differ from the original completely, maybe derived from the RHS (example: 2024_dec_epi_1_model_A)\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "> CURRENT VERSION:\n",
    "## Multi-Agent Pipeline:\n",
    "**version= 003**\n",
    "\n",
    "There are clearly separable problem areas, which will be better managed by detailing and resolving the prompting. An agenda based approach will systematically address extraction challenges by organizing the process into distinct agenda items, each targeting specific aspects of the process:\n",
    "\n",
    "### Agent 1: Initial Extraction\n",
    "- Extract equations from image/PDF using existing MIRA logic\n",
    "- Convert mathematical notation to SymPy code representation\n",
    "- Pass raw code string to next agent\n",
    "\n",
    "### Agent 2: Execution Error Handler\n",
    "- Attempt to execute the extracted SymPy code\n",
    "- Catch and diagnose execution errors (missing imports, undefined variables, syntax errors)\n",
    "- Automatically fix common issues and retry execution\n",
    "- Pass executable code and any remaining warnings forward\n",
    "\n",
    "### Agent 3: Symbol & Parameter Analysis\n",
    "#### Time dependency classification:\n",
    "- Identify all variables that appear with d/dt (time-dependent)\n",
    "- Classify remaining symbols as parameters or independent variables\n",
    "- Flag any inconsistencies in variable usage\n",
    "\n",
    "#### Parameter consistency checking:\n",
    "- Detect parameters that appear in equations but aren't defined\n",
    "- Identify duplicate parameter definitions\n",
    "- Find defined but unused parameters\n",
    "- Check notation consistency (subscripts, superscripts, Greek letters)\n",
    "- Pass comprehensive symbol mapping to next agent\n",
    "\n",
    "### Agent 4: Diagnostic & Scoring\n",
    "- Calculate extraction quality score based on:\n",
    " - Successful execution (from Agent 2)\n",
    " - Symbol consistency (from Agent 3)\n",
    " - Common extraction error patterns\n",
    "- Generate final report with:\n",
    " - Overall confidence score\n",
    " - Specific warnings about potential extraction errors\n",
    " - Recommendations for manual review if score is low\n",
    "- Optional: Include lightweight mathematical validation (missing negative signs, suspicious parameter usage)\n",
    "\n",
    "This pipeline transforms the single-shot extraction into a robust, multi-step process where each agent specializes in one aspect of validation and correction. Since each agent requires a distinct approach and prompt configuration, the LLM can achieve better focus (rather than receiving a summarized, less detailed message).\n",
    "\n",
    "Other possible agenda items:\n",
    "\n",
    "6. Symbol Validation – Are all variables and parameters defined? this focuses more on JSON\n",
    "\n",
    "7. Biological Context Tagging – Are compartments semantically labeled (e.g., S = susceptible)?\n",
    "\n",
    "8. JSON Structure Integrity – Is the output JSON consistent and complete?\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
